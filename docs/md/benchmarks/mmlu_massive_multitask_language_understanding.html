<h1 id="mmlu-massive-multitask-language-understanding">MMLU (Massive
Multitask Language Understanding)</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2020-09-07</p>
<p><strong>Name</strong>: MMLU Massive Multitask Language
Understanding</p>
<p><strong>Domain</strong>: Multidomain</p>
<p><strong>Focus</strong>: Academic knowledge and reasoning across 57
subjects</p>
<p><strong>Keywords</strong>: multitask, multiple-choice, zero-shot,
few-shot, knowledge probing</p>
<p><strong>Task Types</strong>: Multiple choice</p>
<p><strong>Metrics</strong>: Accuracy</p>
<p><strong>Models</strong>: GPT-4o, Gemini 1.5 Pro, o1, DeepSeek-R1</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Dan Hendrycks, Collin Burns, and Saurav Kadavath. Measuring
massive multitask language understanding. 2021. URL:
https://arxiv.org/abs/2009.03300.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{hendrycks2021measuring,</p>
<pre><code>title={Measuring Massive Multitask Language Understanding},

author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav},

journal={arXiv preprint arXiv:2009.03300},

year={2021},

url={https://arxiv.org/abs/2009.03300}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> No instructions to download or run data
given on the site</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> No system constraints</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Meets all FAIR principles and properly
versioned.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Fully defined, represents a solution’s
performance.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 2</p></li>
<li><p><strong>Reason:</strong> Reference models are available
i.e. GPT-3 , but are not trainable or publicly documented</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Well-explained in a provided
paper.</p></li>
</ul>
<p><strong>Average Rating:</strong> 3.5</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/mmlu_massive_multitask_language_understanding_radar.png"
alt="Mmlu Massive Multitask Language Understanding radar plot" /></p>

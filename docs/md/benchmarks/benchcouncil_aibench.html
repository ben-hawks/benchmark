<h1 id="benchcouncil-aibench">BenchCouncil AIBench</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2020-01-01</p>
<p><strong>Name</strong>: BenchCouncil AIBench</p>
<p><strong>Domain</strong>: General</p>
<p><strong>Focus</strong>: End-to-end AI benchmarking across micro,
component, and application levels</p>
<p><strong>Keywords</strong>: benchmarking, AI systems,
application-level evaluation</p>
<p><strong>Task Types</strong>: Training, Inference, End-to-end AI
workloads</p>
<p><strong>Metrics</strong>: Throughput, Latency, Accuracy</p>
<p><strong>Models</strong>: ResNet, BERT, GANs, Recommendation
systems</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Wanling Gao, Fei Tang, Lei Wang, Jianfeng Zhan, Chunxin Lan,
Chunjie Luo, Yunyou Huang, Chen Zheng, Jiahui Dai, Zheng Cao, Daoyi
Zheng, Haoning Tang, Kunlin Zhan, Biao Wang, Defei Kong, Tong Wu, Minghe
Yu, Chongkang Tan, Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu
Wang, Xiaoyu Wang, and Hainan Ye. Aibench: an industry standard internet
service ai benchmark suite. 2019. URL: https://arxiv.org/abs/1908.08998,
arXiv:1908.08998.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{gao2019aibenchindustrystandardinternet,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Wanling Gao and Fei Tang and Lei Wang and Jianfeng Zhan and Chunxin Lan and Chunjie Luo and Yunyou Huang and Chen Zheng and Jiahui Dai and Zheng Cao and Daoyi Zheng and Haoning Tang and Kunlin Zhan and Biao Wang and Defei Kong and Tong Wu and Minghe Yu and Chongkang Tan and Huan Li and Xinhui Tian and Yatao Li and Junchao Shao and Zhenyu Wang and Xiaoyu Wang and Hainan Ye},

eprint        = {1908.08998},

primaryclass  = {cs.CV},

title         = {AIBench: An Industry Standard Internet Service AI Benchmark Suite},

url           = {https://arxiv.org/abs/1908.08998},

year          = {2019}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> No containerized or automated
implementation provided for full benchmark suite</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Task coverage is broad and well-scoped,
but system constraints and expected outputs are not uniformly
defined</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Multiple datasets are mentioned, but not
consistently FAIR-documented, versioned, or linked</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Metrics are appropriate, but
standardization and reproducibility across tasks vary</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Reference models e.g., ResNet, BERT
described; no turnkey implementation or results repository for all
levels</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Paper is comprehensive, but minimal
user-facing documentation or structured reproduction guide</p></li>
</ul>
<p><strong>Average Rating:</strong> 3.333</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/benchcouncil_aibench_radar.png"
alt="Benchcouncil Aibench radar plot" /></p>

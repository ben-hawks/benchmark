- date: '2024-11-13'
  version: v1.0
  last_updated: 2024-11
  expired: unknown
  valid: 'yes'
  valid_date: '2024-11-13'
  name: LLMs for Crop Science
  url: https://openreview.net/forum?id=hMj6jZ6JWU#discussion
  doi: N/A
  domain:
  - Climate & Earth Science
  focus: Evaluating LLMs on crop trait QA and textual inference tasks with domain-specific prompts
  keywords:
  - crop science
  - prompt engineering
  - domain adaptation
  - question answering
  summary: 'Establishes a benchmark of over 5000 expert-annotated QA pairs and prompts in Chinese and English, covering crop
    traits, growth stages, and environmental interactions. Tests GPT-style LLMs on accuracy and domain reasoning using in-context,
    chain-of-thought, and retrieval-augmented prompts.

    '
  licensing: CC-BY-NC-4.0
  task_types:
  - Question Answering
  - Inference
  ai_capability_measured:
  - Scientific knowledge
  - crop reasoning
  metrics:
  - Accuracy
  - F1 score
  models:
  - GPT-3.5
  - GPT-4
  - Claude-3-opus
  - Qwen-max
  - LLama3-8B
  - InternLM2-7B
  - Qwen1.5-7B
  ml_motif:
  - Reasoning & Generalization
  type: Dataset
  ml_task:
  - QA, inference
  solutions: Solution details are described in the referenced paper or repository.
  notes: 'Includes examples with retrieval-augmented and chain-of-thought prompt templates; supports few-shot adaptation.

    '
  contact:
    name: Deepak Patel
    email: unknown
  cite:
  - '@inproceedings{zhang2024empowering,

    title={Empowering and Assessing the Utility of Large Language Models in Crop Science},

    author={Hang Zhang and Jiawei Sun and Renqi Chen and Wei Liu and Zhonghang Yuan and Xinzhe Zheng and Zhefan Wang and Zhiyuan
    Yang and Hang Yan and Han-Sen Zhong and Xiqing Wang and Wanli Ouyang and Fan Yang and Nanqing Dong},

    booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},

    year={2024},

    url={https://openreview.net/forum?id=hMj6jZ6JWU}

    }

    '
  datasets:
    links:
    - name: CROP Dataset (Train Split)
      url: https://huggingface.co/datasets/AI4Agr/CROP-dataset
    - name: CROP Benchmark (Test Split)
      url: https://huggingface.co/datasets/AI4Agr/CROP-benchmark
  results:
    links:
    - name: Empowering and Assessing the Utility of Large Language Models in Crop Science - Experiments
      url: https://renqichen.github.io/The_Crop/
  fair:
    reproducible: 'Yes'
    benchmark_ready: 'Yes'
  ratings:
    software:
      rating: 5
      reason: 'Code for evaluation and training of multiple models is available and well documented. Environment details are
        provided.

        '
    specification:
      rating: 4
      reason: 'Tasks are clearly defined (QA, inference) with structured input/output formats, though no system constraints
        are provided.

        '
    dataset:
      rating: 5
      reason: 'Dataset adheres to all FAIR principles, is well-documented, and publicly available on Hugging Face. Train/Test
        splits are provided across two Huggingface datasets.

        '
    metrics:
      rating: 4
      reason: 'Accuracy is mentioned in the README and webpage as an evaluation metric,

        '
    reference_solution:
      rating: 5
      reason: 'A reference solution is available and well documented. Training code is provided for multiple open weight models.

        '
    documentation:
      rating: 5
      reason: 'The benchmark is well documented with a detailed paper, README, and webpage. Instructions for reproducing results
        are clear.

        '

# GPQA Diamond

**Date**: 2023-11-20

**Expiration**: 

**Valid**: yes

**Name**: GPQA Diamond

**URL**: https://arxiv.org/abs/2311.12022

**Domain**: Science

**Focus**: Graduate-level scientific reasoning

**Keywords**: Google-proof, graduate-level, science QA, chemistry, physics

**Description**: GPQA is a dataset of 448 challenging, multiple-choice questions in biology, physics, and chemistry, written by domain experts. It is “Google-proof”—experts score 65%   74% after error correction  while skilled non-experts with web access score only 34%.  State-of-the-art LLMs like GPT-4 reach around 39% accuracy. 

**Task Types**: Multiple choice, Multi-step QA

**AI Capability**: Scientific reasoning, deep knowledge

**Metrics**: Accuracy

**Models**: o1, DeepSeek-R1

**Notes**: Good

**Citation**:

-
  - type: misc
  - id: rein2023gpqagraduatelevelgoogleproofqa
  - url: https://arxiv.org/abs/2311.12022
  - year: 2023
  - author: Rein, David and Hou, Betty Li and Stickland, Asa Cooper and others
  - title: GPQA: A Graduate-Level Google-Proof Q and A Benchmark
  - bibtex: |
      @misc{rein2023gpqagraduatelevelgoogleproofqa,
        title={GPQA: A Graduate-Level Google-Proof Q and A Benchmark},
        author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and others},
        year={2023},
        url={https://arxiv.org/abs/2311.12022}
      }


# MMLU (Massive Multitask Language Understanding)

**Date**: 2020-09-07

**Expiration**: None

**Valid**: yes

**Name**: MMLU  Massive Multitask Language Understanding 

**URL**: https://paperswithcode.com/dataset/mmlu

**Domain**: Multidomain

**Focus**: Academic knowledge and reasoning across 57 subjects

**Keyword**: multitask, multiple-choice, zero-shot, few-shot, knowledge probing

**Description**: Measuring Massive Multitask Language Understanding  MMLU  is a benchmark of 57  multiple-choice tasks covering elementary mathematics, US history, computer science,  law, and more, designed to evaluate a model's breadth and depth of knowledge in  zero-shot and few-shot settings. 

**Task Types**: Multiple choice

**AI Capability**: General reasoning, subject-matter understanding

**Metrics**: Accuracy

**Models**: GPT-4o, Gemini 1.5 Pro, o1, DeepSeek-R1

**Notes**: Good

**Citation**: @article{hendrycks2021measuring, title={Measuring Massive Multitask Language Understanding}, author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and others}, journal={arXiv preprint arXiv:2009.03300}, year={2021}, url={https://arxiv.org/abs/2009.03300} }


<h1 id="mlperf-hpc">MLPerf HPC</h1>
<p><strong>Date</strong>: 2021-10-20</p>
<p><strong>Name</strong>: MLPerf HPC</p>
<p><strong>Domain</strong>: Cosmology, Climate, Protein Structure,
Catalysis</p>
<p><strong>Focus</strong>: Scientific ML training and inference on HPC
systems</p>
<p><strong>Keywords</strong>: HPC, training, inference, scientific
ML</p>
<p><strong>Task Types</strong>: Training, Inference</p>
<p><strong>Metrics</strong>: Training time, Accuracy, GPU
utilization</p>
<p><strong>Models</strong>: CosmoFlow, DeepCAM, OpenCatalyst</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Steven Farrell, Murali Emani, Jacob Balma, Lukas Drescher,
Aleksandr Drozd, Andreas Fink, Geoffrey Fox, David Kanter, Thorsten
Kurth, Peter Mattson, Dawei Mu, Amit Ruhela, Kento Sato, Koichi
Shirahata, Tsuguchika Tabaru, Aristeidis Tsaris, Jan Balewski, Ben
Cumming, Takumi Danjo, Jens Domke, Takaaki Fukai, Naoto Fukumoto,
Tatsuya Fukushi, Balazs Gerofi, Takumi Honda, Toshiyuki Imamura, Akihiko
Kasagi, Kentaro Kawakami, Shuhei Kudo, Akiyoshi Kuroda, Maxime
Martinasso, Satoshi Matsuoka, Henrique Mendonça, Kazuki Minami, Prabhat
Ram, Takashi Sawada, Mallikarjun Shankar, Tom St. John, Akihiro Tabuchi,
Venkatram Vishwanath, Mohamed Wahib, Masafumi Yamazaki, and Junqi Yin.
Mlperf hpc: a holistic benchmark suite for scientific machine learning
on hpc systems. 2021. URL: https://arxiv.org/abs/2110.11466,
arXiv:2110.11466.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{farrell2021mlperfhpcholisticbenchmark,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Steven Farrell and Murali Emani and Jacob Balma and Lukas Drescher and Aleksandr Drozd and Andreas Fink and Geoffrey Fox and David Kanter and Thorsten Kurth and Peter Mattson and Dawei Mu and Amit Ruhela and Kento Sato and Koichi Shirahata and Tsuguchika Tabaru and Aristeidis Tsaris and Jan Balewski and Ben Cumming and Takumi Danjo and Jens Domke and Takaaki Fukai and Naoto Fukumoto and Tatsuya Fukushi and Balazs Gerofi and Takumi Honda and Toshiyuki Imamura and Akihiko Kasagi and Kentaro Kawakami and Shuhei Kudo and Akiyoshi Kuroda and Maxime Martinasso and Satoshi Matsuoka and Henrique Mendonça and Kazuki Minami and Prabhat Ram and Takashi Sawada and Mallikarjun Shankar and Tom St. John and Akihiro Tabuchi and Venkatram Vishwanath and Mohamed Wahib and Masafumi Yamazaki and Junqi Yin},

eprint        = {2110.11466},

primaryclass  = {cs.LG},

title         = {MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning on HPC Systems},

url           = {https://arxiv.org/abs/2110.11466},

year          = {2021}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Reference implementations exist but
containerization and environment setup require manual effort across HPC
systems.</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Hardware constraints and I/O formats are
not fully defined for all scenarios.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Not all data is independently versioned
or comes with standardized FAIR metadata.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> None</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Reproducibility and environment tuning
depend on system configuration; baseline models not uniformly
bundled.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Central guidance is available but
requires domain-specific effort to replicate results across
systems.</p></li>
</ul>
<p><strong>Average Rating:</strong> 4.167</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/mlperf_hpc_radar.png"
alt="Mlperf Hpc radar plot" /></p>

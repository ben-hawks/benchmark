 | Date | Expiration | Valid | Name | URL | Domain | Focus | Keywords | Description | Task Types | AI Capability | Metrics | Models | Notes | Citation | Ratings | 
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
2024-05-01 |  | yes | Jet Classification | https://github.com/fastmachinelearning/fastml-science/tree/main/jet-classify | Particle Physics | Real-time classification of particle jets using HL-LHC simulation features | classification, real-time ML, jet tagging, QKeras |  | Classification | Real-time inference, model compression performance | Accuracy, AUC | Keras DNN, QKeras quantized DNN | Includes both float and quantized models using QKeras | [^1] |  | 
2024-05-01 |  | yes | Irregular Sensor Data Compression | https://github.com/fastmachinelearning/fastml-science/tree/main/sensor-data-compression | Particle Physics | Real-time compression of sparse sensor data with autoencoders | compression, autoencoder, sparse data, irregular sampling |  | Compression | Reconstruction quality, compression efficiency | MSE, Compression ratio | Autoencoder, Quantized autoencoder | Based on synthetic but realistic physics sensor data | [^2] |  | 
2024-05-01 |  | yes | Beam Control | https://github.com/fastmachinelearning/fastml-science/tree/main/beam-control | Accelerators and Magnets | Reinforcement learning control of accelerator beam position | RL, beam stabilization, control systems, simulation |  | Control | Policy performance in simulated accelerator control | Stability, Control loss | DDPG, PPO (planned) | Environment defined, baseline RL implementation is in progress | [^3], [^4] |  | 
2024-07-08 |  | yes | Ultrafast jet classification at the HL-LHC | https://arxiv.org/pdf/2402.01876 | Particle Physics | FPGA-optimized real-time jet origin classification at the HL-LHC | jet classification, FPGA, quantization-aware training, Deep Sets, Interaction Networks |  | Classification | Real-time inference under FPGA constraints | Accuracy, Latency, Resource utilization | MLP, Deep Sets, Interaction Network | Uses quantization-aware training; hardware synthesis evaluated via hls4ml | [^5] |  | 
2024-10-15 |  | yes | Quench detection | https://indico.cern.ch/event/1387540/contributions/6153618/attachments/2948441/5182077/fast_ml_magnets_2024_final.pdf | Accelerators and Magnets | Real-time detection of superconducting magnet quenches using ML | quench detection, autoencoder, anomaly detection, real-time |  | Anomaly detection, Quench localization | Real-time anomaly detection with multi-modal sensors | ROC-AUC, Detection latency | Autoencoder, RL agents (in development) | Precursor detection in progress; multi-modal and dynamic weighting methods | [^6] |  | 
2024-10-15 |  | yes | DUNE | https://indico.fnal.gov/event/66520/contributions/301423/attachments/182439/250508/fast_ml_dunedaq_sonic_10_15_24.pdf | Particle Physics | Real-time ML for DUNE DAQ time-series data | DUNE, time-series, real-time, trigger |  | Trigger selection, Time-series anomaly detection | Low-latency event detection | Detection efficiency, Latency | CNN, LSTM (planned) | Prototype models demonstrated on SONIC platform | [^7] |  | 
2025-01-08 |  | yes | Intelligent experiments through real-time AI | https://arxiv.org/pdf/2501.04845 | Instrumentation and Detectors; Nuclear Physics; Particle Physics | Real-time FPGA-based triggering and detector control for sPHENIX and future EIC | FPGA, Graph Neural Network, hls4ml, real-time inference, detector control |  | Trigger classification, Detector control, Real-time inference | Low-latency GNN inference on FPGA | Accuracy (charm and beauty detection), Latency (µs), Resource utilization (LUT/FF/BRAM/DSP) | Bipartite Graph Network with Set Transformers (BGN-ST), GarNet (edge-classifier) | Achieved ~97.4% accuracy for beauty decay triggers; sub-10 µs latency on Alveo U280; hit-based FPGA design via hls4ml and FlowGNN. | [^8] |  | 
2025-01-09 |  | yes | Neural Architecture Codesign for Fast Physics Applications | https://arxiv.org/abs/2501.05515 | Physics; Materials Science; Particle Physics | Automated neural architecture search and hardware-efficient model codesign for fast physics applications | neural architecture search, FPGA deployment, quantization, pruning, hls4ml |  | Classification, Peak finding | Hardware-aware model optimization; low-latency inference | Accuracy, Latency, Resource utilization | NAC-based BraggNN, NAC-optimized Deep Sets (jet) | Demonstrated two case studies (materials science, HEP); pipeline and code open-sourced. | [^9] |  | 
2024-06-24 |  | yes | Smart Pixels for LHC | https://arxiv.org/abs/2406.14860 | Particle Physics; Instrumentation and Detectors | On-sensor, in-pixel ML filtering for high-rate LHC pixel detectors | smart pixel, on-sensor inference, data reduction, trigger |  | Image Classification, Data filtering | On-chip, low-power inference; data reduction | Data rejection rate, Power per pixel | 2-layer pixel NN | Prototype in CMOS 28 nm; proof-of-concept for Phase III pixel upgrades. | [^10] |  | 
2023-10-03 |  | yes | HEDM BraggNN | https://arxiv.org/abs/2008.08198 | Material Science | Fast Bragg peak analysis using deep learning in diffraction microscopy | BraggNN, diffraction, peak finding, HEDM |  | Peak detection | High-throughput peak localization | Localization accuracy, Inference time | BraggNN | Enables real-time HEDM workflows; basis for NAC case study. | [^11] |  | 
2023-12-03 |  | yes | 4D-STEM | https://openreview.net/pdf?id=7yt3N0o0W9 | Material Science | Real-time ML for scanning transmission electron microscopy | 4D-STEM, electron microscopy, real-time, image processing |  | Image Classification, Streamed data inference | Real-time large-scale microscopy inference | Classification accuracy, Throughput | CNN models (prototype) | In-progress; model design under development. | [^12] |  | 
2023-12-05 |  | yes | In-Situ High-Speed Computer Vision | https://arxiv.org/abs/2312.00128 | Fusion/Plasma | Real-time image classification for in-situ plasma diagnostics | plasma, in-situ vision, real-time ML |  | Image Classification | Real-time diagnostic inference | Accuracy, FPS | CNN | Embedded/deployment details in progress. | [^13] |  | 
2020-01-01 |  | yes | BenchCouncil AIBench | https://www.benchcouncil.org/AIBench/ | General | End-to-end AI benchmarking across micro, component, and application levels | benchmarking, AI systems, application-level evaluation |  | Training, Inference, End-to-end AI workloads | System-level AI workload performance | Throughput, Latency, Accuracy | ResNet, BERT, GANs, Recommendation systems | Covers scenario-distilling, micro, component, and end-to-end benchmarks. | [^14] |  | 
2020-01-01 |  | yes | BenchCouncil BigDataBench | https://www.benchcouncil.org/BigDataBench/ | General | Big data and AI benchmarking across structured, semi-structured, and unstructured data workloads | big data, AI benchmarking, data analytics |  | Data preprocessing, Inference, End-to-end data pipelines | Data processing and AI model inference performance at scale | Data throughput, Latency, Accuracy | CNN, LSTM, SVM, XGBoost | Built on eight data motifs; provides Hadoop, Spark, Flink, MPI implementations. | [^15] |  | 
2021-10-20 |  | yes | MLPerf HPC | https://github.com/mlcommons/hpc | Cosmology, Climate, Protein Structure, Catalysis | Scientific ML training and inference on HPC systems | HPC, training, inference, scientific ML |  | Training, Inference | Scaling efficiency, training time, model accuracy on HPC | Training time, Accuracy, GPU utilization | CosmoFlow, DeepCAM, OpenCatalyst | Shared framework with MLCommons Science; reference implementations included. | [^16] |  | 
2023-06-01 |  | yes | MLCommons Science | https://github.com/mlcommons/science | Earthquake, Satellite Image, Drug Discovery, Electron Microscope, CFD | AI benchmarks for scientific applications including time-series, imaging, and simulation | science AI, benchmark, MLCommons, HPC |  | Time-series analysis, Image classification, Simulation surrogate modeling | Inference accuracy, simulation speed-up, generalization | MAE, Accuracy, Speedup vs simulation | CNN, GNN, Transformer | Joint national-lab effort under Apache-2.0 license. | [^17] |  | 
2021-07-05 |  | yes | LHC New Physics Dataset | https://arxiv.org/pdf/2107.02157 | Particle Physics; Real-time Triggering | Real-time LHC event filtering for anomaly detection using proton collision data | anomaly detection, proton collision, real-time inference, event filtering, unsupervised ML |  | Anomaly detection, Event classification | Unsupervised signal detection under latency and bandwidth constraints | ROC-AUC, Detection efficiency | Autoencoder, Variational autoencoder, Isolation forest | Includes electron/muon-filtered background and black-box signal benchmarks; 1M events per black box. | [^18] |  | 
2023-07-17 |  | yes | MLCommons Medical AI | https://github.com/mlcommons/medical | Healthcare; Medical AI | Federated benchmarking and evaluation of medical AI models across diverse real-world clinical data | medical AI, federated evaluation, privacy-preserving, fairness, healthcare benchmarks |  | Federated evaluation, Model validation | Clinical accuracy, fairness, generalizability, privacy compliance | ROC AUC, Accuracy, Fairness metrics | MedPerf-validated CNNs, GaNDLF workflows | Open-source platform under Apache-2.0; used across 20+ institutions and hospitals :contentReference[oaicite:2]{index=2}. | [^19] |  | 
2024-10-28 |  | yes | CaloChallenge 2022 | http://arxiv.org/abs/2410.21611 | LHC Calorimeter; Particle Physics | Fast generative-model-based calorimeter shower simulation evaluation | calorimeter simulation, generative models, surrogate modeling, LHC, fast simulation |  | Surrogate modeling | Simulation fidelity, speed, efficiency | Histogram similarity, Classifier AUC, Generation latency | VAE variants, GAN variants, Normalizing flows, Diffusion models | The most comprehensive survey to date on ML-based calorimeter simulation; 31 submissions over different dataset sizes. | [^20] |  | 
ongoing |  | yes | Papers With Code- SOTA Platform | https://paperswithcode.com/sota | General ML; All domains | Open platform tracking state-of-the-art results, benchmarks, and implementations across ML tasks and papers | leaderboard, benchmarking, reproducibility, open-source |  | Multiple (Classification, Detection, NLP, etc.) | Model performance across tasks (accuracy, F1, BLEU, etc.) | Task-specific (Accuracy, F1, BLEU, etc.) | All published models with code | Community-driven open platform; automatic data extraction and versioning. | [^21] |  | 
2022-01-01 |  | yes | Codabench | https://www.codabench.org/ | General ML; Multiple | Open-source platform for organizing reproducible AI benchmarks and competitions | benchmark platform, code submission, competitions, meta-benchmark |  | Multiple | Model reproducibility, performance across datasets | Submission count, Leaderboard ranking, Task-specific metrics | Arbitrary code submissions | Hosts 51 public competitions, ~26 k users, 177 k submissions :contentReference[oaicite:2]{index=2} | [^22] |  | 
2021-09-27 |  | yes | Sabath - SBI-FAIR | https://sbi-fair.github.io/docs/software/sabath/ | Systems; Metadata | FAIR metadata framework for ML-driven surrogate workflows in HPC systems | meta-benchmark, metadata, HPC, surrogate modeling |  | Systems benchmarking | Metadata tracking, reproducible HPC workflows | Metadata completeness, FAIR compliance | N/A | Developed by PI Piotr Luszczek at UTK; integrates with MiniWeatherML, AutoPhaseNN, Cosmoflow, etc. :contentReference[oaicite:4]{index=4} | [^23] |  | 
2022-10-13 |  | yes | PDEBench | https://github.com/pdebench/PDEBench | CFD; Weather Modeling | Benchmark suite for ML-based surrogates solving time-dependent PDEs | PDEs, CFD, scientific ML, surrogate modeling, NeurIPS |  | Supervised Learning | Time-dependent PDE modeling; physical accuracy | RMSE, boundary RMSE, Fourier RMSE | FNO, U-Net, PINN, Gradient-Based inverse methods | Datasets hosted on DaRUS (DOI:10.18419/darus-2986); contact maintainers by email :contentReference[oaicite:6]{index=6} | [^24] |  | 
2024-12-03 |  | yes | The Well | https://polymathic-ai.org/the_well/ | biological systems, fluid dynamics, acoustic scattering, astrophysical MHD | Foundation model + surrogate dataset spanning 16 physical simulation domains | surrogate modeling, foundation model, physics simulations, spatiotemporal dynamics |  | Supervised Learning | Surrogate modeling, physics-based prediction | Dataset size, Domain breadth | FNO baselines, U-Net baselines | Includes unified API and dataset metadata; see 2025 NeurIPS paper for full benchmark details. Size: 15 TB. :contentReference[oaicite:2]{index=2} | [^25] |  | 
2024-10-31 |  | yes | LLM-Inference-Bench | https://github.com/argonne-lcf/LLM-Inference-Bench | LLM; HPC/inference | Hardware performance benchmarking of LLMs on AI accelerators | LLM, inference benchmarking, GPU, accelerator, throughput |  | Inference Benchmarking | Inference throughput, latency, hardware utilization | Token throughput (tok/s), Latency, Framework-hardware mix performance | LLaMA-2-7B, LLaMA-2-70B, Mistral-7B, Qwen-7B | Licensed under BSD-3, maintained by Argonne; supports GPUs and accelerators. :contentReference[oaicite:4]{index=4} | [^26] |  | 
2023-12-12 |  | yes | SGLang Framework | https://github.com/sgl-project/sglang/tree/main/benchmark | LLM Vision | Fast serving framework for LLMs and vision-language models | LLM serving, vision-language, RadixAttention, performance, JSON decoding |  | Model serving framework | Serving throughput, JSON/task-specific latency | Tokens/sec, Time-to-first-token, Throughput gain vs baseline | LLaVA, DeepSeek, Llama | Deployed in production (xAI, NVIDIA, Google Cloud); v0.4.8 release June 2025. :contentReference[oaicite:6]{index=6} | [^27] |  | 
2023-09-12 |  | yes | vLLM Inference and Serving Engine | https://github.com/vllm-project/vllm/tree/main/benchmarks | LLM; HPC/inference | High-throughput, memory-efficient inference and serving engine for LLMs | LLM inference, PagedAttention, CUDA graph, streaming API, quantization |  | Inference Benchmarking | Throughput, latency, memory efficiency | Tokens/sec, Time to First Token (TTFT), Memory footprint | LLaMA, Mixtral, FlashAttention-based models | Incubated by LF AI and Data; achieves up to 24x throughput over HuggingFace Transformers | [^28] |  | 
2022-06-22 |  | yes | vLLM Performance Dashboard | https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/ | LLM; HPC/inference | Interactive dashboard showing inference performance of vLLM | Dashboard, Throughput visualization, Latency analysis, Metric tracking |  | Performance visualization | Throughput, latency, hardware utilization | Tokens/sec, TTFT, Memory usage | LLaMA-2, Mistral, Qwen | Built using ObservableHQ; integrates live data from vLLM benchmarks. | [^29] |  | 
2022-04-01 |  | yes | Nixtla NeuralForecast | https://github.com/Nixtla/neuralforecast | Time-series forecasting; General ML | High-performance neural forecasting library with >30 models | time-series, neural forecasting, NBEATS, NHITS, TFT, probabilistic forecasting, usability |  | Time-series forecasting | Forecast accuracy, interpretability, speed | RMSE, MAPE, CRPS | NBEATS, NHITS, TFT, DeepAR | AutoModel supports hyperparameter tuning and distributed execution via Ray and Optuna. First official NHITS implementation. | [^30] |  | 
2023-06-01 |  | yes | Nixtla Neural Forecast NHITS | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Official NHITS implementation for long-horizon time series forecasting | NHITS, long-horizon forecasting, neural interpolation, time-series |  | Time-series forecasting | Accuracy, compute efficiency for long series | RMSE, MAPE | NHITS | Official implementation in NeuralForecast, included since its AAAI 2023 release. | [^31] |  | 
2023-10-03 |  | yes | Nixtla Neural Forecast TimeLLM | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Reprogramming LLMs for time series forecasting | Time-LLM, language model, time-series, reprogramming |  | Time-series forecasting | Model reuse via LLM, few-shot forecasting | RMSE, MAPE | Time-LLM | Fully open-source; transforms forecasting using LLM text reconstruction. | [^32] |  | 
2023-10-05 |  | yes | Nixtla Neural Forecast TimeGPT | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Time-series foundation model "TimeGPT" for forecasting and anomaly detection | TimeGPT, foundation model, time-series, generative model |  | Time-series forecasting, Anomaly detection | Zero-shot forecasting, anomaly detection | RMSE, Anomaly detection metrics | TimeGPT | Offered via Nixtla API and Azure Studio; enterprise-grade support available. | [^33] |  | 
2025-03-03 |  | yes | HDR ML Anomaly Challenge- Gravitational Waves | https://www.codabench.org/competitions/2626/ | Astrophysics; Time-series | Detecting anomalous gravitational-wave signals from LIGO/Virgo datasets | anomaly detection, gravitational waves, astrophysics, time-series |  | Anomaly detection | Novel event detection in physical signals | ROC-AUC, Precision/Recall | Deep latent CNNs, Autoencoders | NSF HDR A3D3 sponsored; prize pool and starter kit provided on Codabench. :contentReference[oaicite:2]{index=2} | [^34] |  | 
2025-03-03 |  | yes | HDR ML Anomaly Challenge- Butterfly | https://www.codabench.org/competitions/3764/ | Genomics; Image/CV | Detecting hybrid butterflies via image anomaly detection in genomic-informed dataset | anomaly detection, computer vision, genomics, butterfly hybrids |  | Anomaly detection | Hybrid detection in biological systems | Classification accuracy, F1 score | CNN-based detectors | Hybrid detection benchmarks hosted on Codabench. :contentReference[oaicite:4]{index=4} | [^35] |  | 
2025-03-03 |  | yes | HDR ML Anomaly Challenge- Sea Level Rise | https://www.codabench.org/competitions/3223/ | Climate Science; Time-series, Image/CV | Detecting anomalous sea-level rise and flooding events via time-series and satellite imagery | anomaly detection, climate science, sea-level rise, time-series, remote sensing |  | Anomaly detection | Detection of environmental anomalies | ROC-AUC, Precision/Recall | CNNs, RNNs, Transformers | Sponsored by NSF HDR; integrates sensor and satellite data. :contentReference[oaicite:6]{index=6} | [^36] |  | 
2025-01-24 |  | yes | Single Qubit Readout on QICK System | https://github.com/fastmachinelearning/ml-quantum-readout | Quantum Computing | Real-time single-qubit state classification using FPGA firmware | qubit readout, hls4ml, FPGA, QICK |  | Classification | Single-shot fidelity, inference latency | Accuracy, Latency | hls4ml quantized NN | Achieves ~96% fidelity with ~32 ns latency and low FPGA resource utilization. :contentReference[oaicite:1]{index=1} | [^37] |  | 
2023-11-20 |  | yes | GPQA A Graduate Level Google Proof Question and Answer Benchmark | https://arxiv.org/abs/2311.12022 | Science (Biology, Physics, Chemistry) | Graduate-level, expert-validated multiple-choice questions hard even with web access | Google-proof, multiple-choice, expert reasoning, science QA |  | Multiple choice | Scientific reasoning, knowledge probing | Accuracy | GPT-4 baseline | “Google-proof”; supports oversight research. | [^38] |  | 
2024-12-13 |  | yes | SeafloorAI | https://neurips.cc/virtual/2024/poster/97432 | Marine Science; Vision-Language | Large-scale vision-language dataset for seafloor mapping and geological classification | sonar imagery, vision-language, seafloor mapping, segmentation, QA |  | Image segmentation, Vision-language QA | Geospatial understanding, multimodal reasoning | Segmentation pixel accuracy, QA accuracy | SegFormer, ViLT-style multimodal models | Data processing code publicly available, covering five geological layers; curated with marine scientists :contentReference[oaicite:2]{index=2}. | [^39] |  | 
2024-12-13 |  | yes | SuperCon3D | https://neurips.cc/virtual/2024/poster/97553 | Materials Science; Superconductivity | Dataset and models for predicting and generating high-Tc superconductors using 3D crystal structures | superconductivity, crystal structures, equivariant GNN, generative models |  | Regression (Tc prediction), Generative modeling | Structure-to-property prediction, structure generation | MAE (Tc), Validity of generated structures | SODNet, DiffCSP-SC | Demonstrates advantage of combining ordered and disordered structural data in model design :contentReference[oaicite:4]{index=4}. | [^40] |  | 
2024-12-13 |  | yes | GeSS | https://neurips.cc/virtual/2024/poster/97816 | Scientific ML; Geometric Deep Learning | Benchmark suite evaluating geometric deep learning models under real-world distribution shifts | geometric deep learning, distribution shift, OOD robustness, scientific applications |  | Classification, Regression | OOD performance in scientific settings | Accuracy, RMSE, OOD robustness delta | GCN, EGNN, DimeNet++ | Includes no-OOD, unlabeled-OOD, and few-label scenarios :contentReference[oaicite:6]{index=6}. | [^41] |  | 
2024-12-13 |  | yes | Vocal Call Locator | https://neurips.cc/virtual/2024/poster/97470 | Neuroscience; Bioacoustics | Benchmarking sound-source localization of rodent vocalizations from multi-channel audio | source localization, bioacoustics, time-series, SSL |  | Sound source localization | Source localization accuracy in bioacoustic settings | Localization error (cm), Recall/Precision | CNN-based SSL models | Dataset spans real, simulated, and mixed audio; supports benchmarking across data types :contentReference[oaicite:2]{index=2}. | [^42] |  | 
2024-12-13 |  | yes | MassSpecGym | https://neurips.cc/virtual/2024/poster/97823 | Cheminformatics; Molecular Discovery | Benchmark suite for discovery and identification of molecules via MS/MS | mass spectrometry, molecular structure, de novo generation, retrieval, dataset |  | De novo generation, Retrieval, Simulation | Molecular identification and generation from spectral data | Structure accuracy, Retrieval precision, Simulation MSE | Graph-based generative models, Retrieval baselines | Dataset~>1M spectra; open-source GitHub repo; widely cited as a go-to benchmark for MS/MS tasks :contentReference[oaicite:4]{index=4}. | [^43] |  | 
2024-12-13 |  | yes | Urban Data Layer | https://neurips.cc/virtual/2024/poster/97837 | Urban Computing; Data Engineering | Unified data pipeline for multi-modal urban science research | data pipeline, urban science, multi-modal, benchmark |  | Prediction, Classification | Multi-modal urban inference, standardization | Task-specific accuracy or RMSE | Baseline regression/classification pipelines | Source code available on GitHub (SJTU-CILAB/udl); promotes reusable urban-science foundation models :contentReference[oaicite:6]{index=6}. | [^44] |  | 
2024-12-13 |  | yes | Delta Squared-DFT | https://neurips.cc/virtual/2024/poster/97788 | Computational Chemistry; Materials Science | Benchmarking machine-learning corrections to DFT using Delta Squared-trained models for reaction energies | density functional theory, Delta Squared-ML correction, reaction energetics, quantum chemistry |  | Regression | High-accuracy energy prediction, DFT correction | Mean Absolute Error (eV), Energy ranking accuracy | Delta Squared-ML correction networks, Kernel ridge regression | Demonstrates CC-level accuracy with ~1% of high-level data. Benchmarks publicly included for reproducibility. | [^45] |  | 
2024-12-13 |  | yes | LLMs for Crop Science | https://neurips.cc/virtual/2024/poster/97570 | Agricultural Science; NLP | Evaluating LLMs on crop trait QA and textual inference tasks with domain-specific prompts | crop science, prompt engineering, domain adaptation, question answering |  | Question Answering, Inference | Scientific knowledge, crop reasoning | Accuracy, F1 score | GPT-4, LLaMA-2-13B, T5-XXL | Includes examples with retrieval-augmented and chain-of-thought prompt templates; supports few-shot adaptation. | [^46] |  | 
2024-12-13 |  | yes | SPIQA LLM | https://neurips.cc/virtual/2024/poster/97575 | Multimodal Scientific QA; Computer Vision | Evaluating LLMs on image-based scientific paper figure QA tasks (LLM Adapter performance) | multimodal QA, scientific figures, image+text, chain-of-thought prompting |  | Multimodal QA | Visual reasoning, scientific figure understanding | Accuracy, F1 score | LLaVA, MiniGPT-4, Owl-LLM adapter variants | Companion to SPIQA main benchmark; compares adapter strategies using same images and QA pairs. | [^47] |  | 

[^1]: Javier Duarte, Nhan Tran, Ben Hawks, Christian Herwig, Jules Muhizi, Shvetank Prakash, and Vijay Janapa Reddi. Fastml science benchmarks: accelerating real-time scientific edge machine learning. 2022. URL: https://arxiv.org/abs/2207.07958, arXiv:2207.07958.
[^2]: Javier Duarte, Nhan Tran, Ben Hawks, Christian Herwig, Jules Muhizi, Shvetank Prakash, and Vijay Janapa Reddi. Fastml science benchmarks: accelerating real-time scientific edge machine learning. 2022. URL: https://arxiv.org/abs/2207.07958, arXiv:2207.07958.
[^3]: Diana Kafkes and Jason St. John. Boostr: a dataset for accelerator control systems. 2021. URL: https://arxiv.org/abs/2101.08359, arXiv:2101.08359.
[^4]: Javier Duarte, Nhan Tran, Ben Hawks, Christian Herwig, Jules Muhizi, Shvetank Prakash, and Vijay Janapa Reddi. Fastml science benchmarks: accelerating real-time scientific edge machine learning. 2022. URL: https://arxiv.org/abs/2207.07958, arXiv:2207.07958.
[^5]: Could not parse citation: 
[^6]: Could not parse citation: 
[^7]: Could not parse citation: 
[^8]: J. Kvapil, G. Borca-Tasciuc, H. Bossi, K. Chen, Y. Chen, Y. Corrales Morales, H. Da Costa, C. Da Silva, C. Dean, J. Durham, S. Fu, C. Hao, P. Harris, O. Hen, H. Jheng, Y. Lee, P. Li, X. Li, Y. Lin, M. X. Liu, V. Loncar, J. P. Mitrevski, A. Olvera, M. L. Purschke, J. S. Renck, G. Roland, J. Schambach, Z. Shi, N. Tran, N. Wuerfel, B. Xu, D. Yu, and H. Zhang. Intelligent experiments through real-time ai: fast data processing and autonomous detector control for sphenix and future eic detectors. 2025. URL: https://arxiv.org/abs/2501.04845, arXiv:2501.04845.
[^9]: Jason Weitz, Dmitri Demler, Luke McDermott, Nhan Tran, and Javier Duarte. Neural architecture codesign for fast physics applications. 2025. URL: https://arxiv.org/abs/2501.05515, arXiv:2501.05515.
[^10]: Benjamin Parpillon, Chinar Syal, Jieun Yoo, Jennet Dickinson, Morris Swartz, Giuseppe Di Guglielmo, Alice Bean, Douglas Berry, Manuel Blanco Valentin, Karri DiPetrillo, Anthony Badea, Lindsey Gray, Petar Maksimovic, Corrinne Mills, Mark S. Neubauer, Gauri Pradhan, Nhan Tran, Dahai Wen, and Farah Fahim. Smart pixels: in-pixel ai for on-sensor data filtering. 2024. URL: https://arxiv.org/abs/2406.14860, arXiv:2406.14860.
[^11]: Zhengchun Liu, Hemant Sharma, Jun-Sang Park, Peter Kenesei, Antonino Miceli, Jonathan Almer, Rajkumar Kettimuthu, and Ian Foster. Braggnn: fast x-ray bragg peak analysis using deep learning. 2021. URL: https://arxiv.org/abs/2008.08198, arXiv:2008.08198.
[^12]: Shuyu Qin, Joshua Agar, and Nhan Tran. Extremely noisy 4d-tem strain mapping using cycle consistent spatial transforming autoencoders. In AI for Accelerated Materials Design - NeurIPS 2023 Workshop. 2023. URL: https://openreview.net/forum?id=7yt3N0o0W9.
[^13]: Y. Wei, R. F. Forelli, C. Hansen, J. P. Levesque, N. Tran, J. C. Agar, G. Di Guglielmo, M. E. Mauel, and G. A. Navratil. Low latency optical-based mode tracking with machine learning deployed on fpgas on a tokamak. Review of Scientific Instruments, July 2024. URL: http://dx.doi.org/10.1063/5.0190354, doi:10.1063/5.0190354.
[^14]: Wanling Gao, Fei Tang, Lei Wang, Jianfeng Zhan, Chunxin Lan, Chunjie Luo, Yunyou Huang, Chen Zheng, Jiahui Dai, Zheng Cao, Daoyi Zheng, Haoning Tang, Kunlin Zhan, Biao Wang, Defei Kong, Tong Wu, Minghe Yu, Chongkang Tan, Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu Wang, Xiaoyu Wang, and Hainan Ye. Aibench: an industry standard internet service ai benchmark suite. 2019. URL: https://arxiv.org/abs/1908.08998, arXiv:1908.08998.
[^15]: Wanling Gao, Jianfeng Zhan, Lei Wang, Chunjie Luo, Daoyi Zheng, Xu Wen, Rui Ren, Chen Zheng, Xiwen He, Hainan Ye, Haoning Tang, Zheng Cao, Shujie Zhang, and Jiahui Dai. Bigdatabench: a scalable and unified big data and ai benchmark suite. 2018. URL: https://arxiv.org/abs/1802.08254, arXiv:1802.08254.
[^16]: Steven Farrell, Murali Emani, Jacob Balma, Lukas Drescher, Aleksandr Drozd, Andreas Fink, Geoffrey Fox, David Kanter, Thorsten Kurth, Peter Mattson, Dawei Mu, Amit Ruhela, Kento Sato, Koichi Shirahata, Tsuguchika Tabaru, Aristeidis Tsaris, Jan Balewski, Ben Cumming, Takumi Danjo, Jens Domke, Takaaki Fukai, Naoto Fukumoto, Tatsuya Fukushi, Balazs Gerofi, Takumi Honda, Toshiyuki Imamura, Akihiko Kasagi, Kentaro Kawakami, Shuhei Kudo, Akiyoshi Kuroda, Maxime Martinasso, Satoshi Matsuoka, Henrique Mendonça, Kazuki Minami, Prabhat Ram, Takashi Sawada, Mallikarjun Shankar, Tom St. John, Akihiro Tabuchi, Venkatram Vishwanath, Mohamed Wahib, Masafumi Yamazaki, and Junqi Yin. Mlperf hpc: a holistic benchmark suite for scientific machine learning on hpc systems. 2021. URL: https://arxiv.org/abs/2110.11466, arXiv:2110.11466.
[^17]: MLCommons Science Working Group. Mlcommons science working group benchmarks. 2023. URL: https://github.com/mlcommons/science.
[^18]: Thea Aarrestad, Ekaterina Govorkova, Jennifer Ngadiuba, Ema Puljak, Maurizio Pierini, and Kinga Anna Wozniak. Unsupervised new physics detection at 40 mhz: training dataset. June 2021. URL: https://doi.org/10.5281/zenodo.5046428, doi:10.5281/zenodo.5046428.
[^19]: Alex Karargyris, Micah J Sheller, and others. Federated benchmarking of medical artificial intelligence with medperf. Nature Machine Intelligence, 2023. URL: https://www.nature.com/articles/s42256-023-00652-2.
[^20]: Claudius Krause, Michele Faucci Giannelli, Gregor Kasieczka, Benjamin Nachman, Dalila Salamani, David Shih, Anna Zaborowska, Oz Amram, Kerstin Borras, Matthew R. Buckley, Erik Buhmann, Thorsten Buss, Renato Paulo Da Costa Cardoso, Anthony L. Caterini, Nadezda Chernyavskaya, Federico A. G. Corchia, Jesse C. Cresswell, Sascha Diefenbacher, Etienne Dreyer, Vijay Ekambaram, Engin Eren, Florian Ernst, Luigi Favaro, Matteo Franchini, Frank Gaede, Eilam Gross, Shih-Chieh Hsu, Kristina Jaruskova, Benno Käch, Jayant Kalagnanam, Raghav Kansal, Taewoo Kim, Dmitrii Kobylianskii, Anatolii Korol, William Korcari, Dirk Krücker, Katja Krüger, Marco Letizia, Shu Li, Qibin Liu, Xiulong Liu, Gabriel Loaiza-Ganem, Thandikire Madula, Peter McKeown, Isabell-A. Melzer-Pellmann, Vinicius Mikuni, Nam Nguyen, Ayodele Ore, Sofia Palacios Schweitzer, Ian Pang, Kevin Pedro, Tilman Plehn, Witold Pokorski, Huilin Qu, Piyush Raikwar, John A. Raine, Humberto Reyes-Gonzalez, Lorenzo Rinaldi, Brendan Leigh Ross, Moritz A. W. Scham, Simon Schnake, Chase Shimmin, Eli Shlizerman, Nathalie Soybelman, Mudhakar Srivatsa, Kalliopi Tsolaki, Sofia Vallecorsa, Kyongmin Yeo, and Rui Zhang. Calochallenge 2022: a community challenge for fast calorimeter simulation. 2024. URL: https://arxiv.org/abs/2410.21611, arXiv:2410.21611.
[^21]: Papers With Code. Papers with code: open machine learning benchmarks and leaderboards. 2025. URL: https://paperswithcode.com.
[^22]: Zhen Xu, Sergio Escalera, and others. Codabench: flexible, easy-to-use, and reproducible meta-benchmark platform. Patterns, 3(7):100543, 2022. doi:10.1016/j.patter.2022.100543.
[^23]: Piotr Luszczek and others. Sabath: fair metadata technology for surrogate benchmarks. Technical Report, University of Tennessee, 2021.
[^24]: Makoto Takamoto, Timothy Praditia, Raphael Leiteritz, Dan MacKinlay, Francesco Alesiani, Dirk Pflüger, and Mathias Niepert. Pdebench: an extensive benchmark for scientific machine learning. 2024. URL: https://arxiv.org/abs/2210.07182, arXiv:2210.07182.
[^25]: Ruben Ohana, Michael McCabe, Lucas Meyer, and others. The well: a large-scale collection of diverse physics simulations for machine learning. NeurIPS, 37:44989–45037, 2024.
[^26]: Krishna Teja Chitty-Venkata, Siddhisanket Raskar, Bharat Kale, Farah Ferdaus, Aditya Tanikanti, Ken Raffenetti, Valerie Taylor, Murali Emani, and Venkatram Vishwanath. Llm-inference-bench: inference benchmarking of large language models on ai accelerators. 2024. URL: https://arxiv.org/abs/2411.00136, arXiv:2411.00136.
[^27]: Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Sun, Jeff Huang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E. Gonzalez, Clark Barrett, and Ying Sheng. Sglang: efficient execution of structured language model programs. 2024. URL: https://arxiv.org/abs/2312.07104, arXiv:2312.07104.
[^28]: Woosuk Kwon and others. Efficient memory management for large language model serving with pagedattention. In SOSP 2023. 2023.
[^29]: Simon Mo. Vllm performance dashboard. 2024. URL: https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/.
[^30]: Kin G. Olivares, Cristian Challú, and others. Neuralforecast: user friendly state-of-the-art neural forecasting models. PyCon US, 2022. URL: https://github.com/Nixtla/neuralforecast.
[^31]: Cristian Challu, Kin G. Olivares, and others. Nhits: neural hierarchical interpolation for time series forecasting. In AAAI 2023. 2023.
[^32]: Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y. Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, and Qingsong Wen. Time-llm: time series forecasting by reprogramming large language models. 2024. URL: https://arxiv.org/abs/2310.01728, arXiv:2310.01728.
[^33]: Azul Garza, Cristian Challu, and Max Mergenthaler-Canseco. Timegpt-1. 2024. URL: https://arxiv.org/abs/2310.03589, arXiv:2310.03589.
[^34]: Elizabeth G. Campolongo, Yuan-Tang Chou, Ekaterina Govorkova, Wahid Bhimji, Wei-Lun Chao, Chris Harris, Shih-Chieh Hsu, Hilmar Lapp, Mark S. Neubauer, Josephine Namayanja, Aneesh Subramanian, Philip Harris, Advaith Anand, David E. Carlyn, Subhankar Ghosh, Christopher Lawrence, Eric Moreno, Ryan Raikman, Jiaman Wu, Ziheng Zhang, Bayu Adhi, Mohammad Ahmadi Gharehtoragh, Saúl Alonso Monsalve, Marta Babicz, Furqan Baig, Namrata Banerji, William Bardon, Tyler Barna, Tanya Berger-Wolf, Adji Bousso Dieng, Micah Brachman, Quentin Buat, David C. Y. Hui, Phuong Cao, Franco Cerino, Yi-Chun Chang, Shivaji Chaulagain, An-Kai Chen, Deming Chen, Eric Chen, Chia-Jui Chou, Zih-Chen Ciou, Miles Cochran-Branson, Artur Cordeiro Oudot Choi, Michael Coughlin, Matteo Cremonesi, Maria Dadarlat, Peter Darch, Malina Desai, Daniel Diaz, Steven Dillmann, Javier Duarte, Isla Duporge, Urbas Ekka, Saba Entezari Heravi, Hao Fang, Rian Flynn, Geoffrey Fox, Emily Freed, Hang Gao, Jing Gao, Julia Gonski, Matthew Graham, Abolfazl Hashemi, Scott Hauck, James Hazelden, Joshua Henry Peterson, Duc Hoang, Wei Hu, Mirco Huennefeld, David Hyde, Vandana Janeja, Nattapon Jaroenchai, Haoyi Jia, Yunfan Kang, Maksim Kholiavchenko, Elham E. Khoda, Sangin Kim, Aditya Kumar, Bo-Cheng Lai, Trung Le, Chi-Wei Lee, JangHyeon Lee, Shaocheng Lee, Suzan van der Lee, Charles Lewis, Haitong Li, Haoyang Li, Henry Liao, Mia Liu, Xiaolin Liu, Xiulong Liu, Vladimir Loncar, Fangzheng Lyu, Ilya Makarov, Abhishikth Mallampalli Chen-Yu Mao, Alexander Michels, Alexander Migala, Farouk Mokhtar, Mathieu Morlighem, Min Namgung, Andrzej Novak, Andrew Novick, Amy Orsborn, Anand Padmanabhan, Jia-Cheng Pan, Sneh Pandya, Zhiyuan Pei, Ana Peixoto, George Percivall, Alex Po Leung, Sanjay Purushotham, Zhiqiang Que, Melissa Quinnan, Arghya Ranjan, Dylan Rankin, Christina Reissel, Benedikt Riedel, Dan Rubenstein, Argyro Sasli, Eli Shlizerman, Arushi Singh, Kim Singh, Eric R. Sokol, Arturo Sorensen, Yu Su, Mitra Taheri, Vaibhav Thakkar, Ann Mariam Thomas, Eric Toberer, Chenghan Tsai, Rebecca Vandewalle, Arjun Verma, Ricco C. Venterea, He Wang, Jianwu Wang, Sam Wang, Shaowen Wang, Gordon Watts, Jason Weitz, Andrew Wildridge, Rebecca Williams, Scott Wolf, Yue Xu, Jianqi Yan, Jai Yu, Yulei Zhang, Haoran Zhao, Ying Zhao, and Yibo Zhong. Building machine learning challenges for anomaly detection in science. 2025. URL: https://arxiv.org/abs/2503.02112, arXiv:2503.02112.
[^35]: Elizabeth G. Campolongo, Yuan-Tang Chou, Ekaterina Govorkova, Wahid Bhimji, Wei-Lun Chao, Chris Harris, Shih-Chieh Hsu, Hilmar Lapp, Mark S. Neubauer, Josephine Namayanja, Aneesh Subramanian, Philip Harris, Advaith Anand, David E. Carlyn, Subhankar Ghosh, Christopher Lawrence, Eric Moreno, Ryan Raikman, Jiaman Wu, Ziheng Zhang, Bayu Adhi, Mohammad Ahmadi Gharehtoragh, Saúl Alonso Monsalve, Marta Babicz, Furqan Baig, Namrata Banerji, William Bardon, Tyler Barna, Tanya Berger-Wolf, Adji Bousso Dieng, Micah Brachman, Quentin Buat, David C. Y. Hui, Phuong Cao, Franco Cerino, Yi-Chun Chang, Shivaji Chaulagain, An-Kai Chen, Deming Chen, Eric Chen, Chia-Jui Chou, Zih-Chen Ciou, Miles Cochran-Branson, Artur Cordeiro Oudot Choi, Michael Coughlin, Matteo Cremonesi, Maria Dadarlat, Peter Darch, Malina Desai, Daniel Diaz, Steven Dillmann, Javier Duarte, Isla Duporge, Urbas Ekka, Saba Entezari Heravi, Hao Fang, Rian Flynn, Geoffrey Fox, Emily Freed, Hang Gao, Jing Gao, Julia Gonski, Matthew Graham, Abolfazl Hashemi, Scott Hauck, James Hazelden, Joshua Henry Peterson, Duc Hoang, Wei Hu, Mirco Huennefeld, David Hyde, Vandana Janeja, Nattapon Jaroenchai, Haoyi Jia, Yunfan Kang, Maksim Kholiavchenko, Elham E. Khoda, Sangin Kim, Aditya Kumar, Bo-Cheng Lai, Trung Le, Chi-Wei Lee, JangHyeon Lee, Shaocheng Lee, Suzan van der Lee, Charles Lewis, Haitong Li, Haoyang Li, Henry Liao, Mia Liu, Xiaolin Liu, Xiulong Liu, Vladimir Loncar, Fangzheng Lyu, Ilya Makarov, Abhishikth Mallampalli Chen-Yu Mao, Alexander Michels, Alexander Migala, Farouk Mokhtar, Mathieu Morlighem, Min Namgung, Andrzej Novak, Andrew Novick, Amy Orsborn, Anand Padmanabhan, Jia-Cheng Pan, Sneh Pandya, Zhiyuan Pei, Ana Peixoto, George Percivall, Alex Po Leung, Sanjay Purushotham, Zhiqiang Que, Melissa Quinnan, Arghya Ranjan, Dylan Rankin, Christina Reissel, Benedikt Riedel, Dan Rubenstein, Argyro Sasli, Eli Shlizerman, Arushi Singh, Kim Singh, Eric R. Sokol, Arturo Sorensen, Yu Su, Mitra Taheri, Vaibhav Thakkar, Ann Mariam Thomas, Eric Toberer, Chenghan Tsai, Rebecca Vandewalle, Arjun Verma, Ricco C. Venterea, He Wang, Jianwu Wang, Sam Wang, Shaowen Wang, Gordon Watts, Jason Weitz, Andrew Wildridge, Rebecca Williams, Scott Wolf, Yue Xu, Jianqi Yan, Jai Yu, Yulei Zhang, Haoran Zhao, Ying Zhao, and Yibo Zhong. Building machine learning challenges for anomaly detection in science. 2025. URL: https://arxiv.org/abs/2503.02112, arXiv:2503.02112.
[^36]: Elizabeth G. Campolongo, Yuan-Tang Chou, Ekaterina Govorkova, Wahid Bhimji, Wei-Lun Chao, Chris Harris, Shih-Chieh Hsu, Hilmar Lapp, Mark S. Neubauer, Josephine Namayanja, Aneesh Subramanian, Philip Harris, Advaith Anand, David E. Carlyn, Subhankar Ghosh, Christopher Lawrence, Eric Moreno, Ryan Raikman, Jiaman Wu, Ziheng Zhang, Bayu Adhi, Mohammad Ahmadi Gharehtoragh, Saúl Alonso Monsalve, Marta Babicz, Furqan Baig, Namrata Banerji, William Bardon, Tyler Barna, Tanya Berger-Wolf, Adji Bousso Dieng, Micah Brachman, Quentin Buat, David C. Y. Hui, Phuong Cao, Franco Cerino, Yi-Chun Chang, Shivaji Chaulagain, An-Kai Chen, Deming Chen, Eric Chen, Chia-Jui Chou, Zih-Chen Ciou, Miles Cochran-Branson, Artur Cordeiro Oudot Choi, Michael Coughlin, Matteo Cremonesi, Maria Dadarlat, Peter Darch, Malina Desai, Daniel Diaz, Steven Dillmann, Javier Duarte, Isla Duporge, Urbas Ekka, Saba Entezari Heravi, Hao Fang, Rian Flynn, Geoffrey Fox, Emily Freed, Hang Gao, Jing Gao, Julia Gonski, Matthew Graham, Abolfazl Hashemi, Scott Hauck, James Hazelden, Joshua Henry Peterson, Duc Hoang, Wei Hu, Mirco Huennefeld, David Hyde, Vandana Janeja, Nattapon Jaroenchai, Haoyi Jia, Yunfan Kang, Maksim Kholiavchenko, Elham E. Khoda, Sangin Kim, Aditya Kumar, Bo-Cheng Lai, Trung Le, Chi-Wei Lee, JangHyeon Lee, Shaocheng Lee, Suzan van der Lee, Charles Lewis, Haitong Li, Haoyang Li, Henry Liao, Mia Liu, Xiaolin Liu, Xiulong Liu, Vladimir Loncar, Fangzheng Lyu, Ilya Makarov, Abhishikth Mallampalli Chen-Yu Mao, Alexander Michels, Alexander Migala, Farouk Mokhtar, Mathieu Morlighem, Min Namgung, Andrzej Novak, Andrew Novick, Amy Orsborn, Anand Padmanabhan, Jia-Cheng Pan, Sneh Pandya, Zhiyuan Pei, Ana Peixoto, George Percivall, Alex Po Leung, Sanjay Purushotham, Zhiqiang Que, Melissa Quinnan, Arghya Ranjan, Dylan Rankin, Christina Reissel, Benedikt Riedel, Dan Rubenstein, Argyro Sasli, Eli Shlizerman, Arushi Singh, Kim Singh, Eric R. Sokol, Arturo Sorensen, Yu Su, Mitra Taheri, Vaibhav Thakkar, Ann Mariam Thomas, Eric Toberer, Chenghan Tsai, Rebecca Vandewalle, Arjun Verma, Ricco C. Venterea, He Wang, Jianwu Wang, Sam Wang, Shaowen Wang, Gordon Watts, Jason Weitz, Andrew Wildridge, Rebecca Williams, Scott Wolf, Yue Xu, Jianqi Yan, Jai Yu, Yulei Zhang, Haoran Zhao, Ying Zhao, and Yibo Zhong. Building machine learning challenges for anomaly detection in science. 2025. URL: https://arxiv.org/abs/2503.02112, arXiv:2503.02112.
[^37]: Giuseppe Di Guglielmo, Botao Du, Javier Campos, Alexandra Boltasseva, Akash V. Dixit, Farah Fahim, Zhaxylyk Kudyshev, Santiago Lopez, Ruichao Ma, Gabriel N. Perdue, Nhan Tran, Omer Yesilyurt, and Daniel Bowring. End-to-end workflow for machine learning-based qubit readout with qick and hls4ml. 2025. URL: https://arxiv.org/abs/2501.14663, arXiv:2501.14663.
[^38]: David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: a graduate-level google-proof q&a benchmark. 2023. URL: https://arxiv.org/abs/2311.12022, arXiv:2311.12022.
[^39]: Kien X. Nguyen, Fengchun Qiao, Arthur Trembanis, and Xi Peng. Seafloorai: a large-scale vision-language dataset for seafloor geological survey. 2024. URL: https://arxiv.org/abs/2411.00172, arXiv:2411.00172.
[^40]: Zhong Zuo and others. Supercon3d: learning superconductivity from ordered and disordered material structures. 2024. NeurIPS Poster.
[^41]: Deyu Zou, Shikun Liu, and others. Gess: benchmarking geometric deep learning under scientific applications with distribution shifts. 2024. NeurIPS Poster.
[^42]: Ralph Peterson, Aramis Tanelus, and others. Vocal call locator benchmark for localizing rodent vocalizations. 2024. NeurIPS Poster. URL: https://neurips.cc/virtual/2024/poster/97470.
[^43]: Roman Bushuiev, Anton Bushuiev, and others. Massspecgym: a benchmark for the discovery and identification of molecules. 2024. NeurIPS Spotlight Poster. URL: https://neurips.cc/virtual/2024/poster/97823.
[^44]: Yiheng Wang, Tianyu Wang, and others. Urbandatalayer: a unified data pipeline for urban science. 2024. NeurIPS Poster. URL: https://neurips.cc/virtual/2024/poster/97837.
[^45]: Wei Liu, Rong Chen, and others. Delta squared-dft: machine-learning corrected density functional theory for reaction  energetics. 2024. NeurIPS Poster. URL: https://neurips.cc/virtual/2024/poster/97788.
[^46]: Deepak Patel, Lan Zhao, and others. Large language models for crop science: benchmarking domain reasoning and qa. 2024. NeurIPS Poster. URL: https://neurips.cc/virtual/2024/poster/97570.
[^47]: Xiaoyan Zhong, Yijian Gao, and others. Spiqa-llm: evaluating llm adapters on scientific figure qa. 2024. NeurIPS Poster. URL: https://neurips.cc/virtual/2024/poster/97575.

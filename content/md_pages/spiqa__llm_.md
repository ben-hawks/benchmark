# SPIQA (LLM)

**Date**: 2024-12-13

**Expiration**: 

**Valid**: yes

**Name**: SPIQA  LLM 

**URL**: https://neurips.cc/virtual/2024/poster/97575

**Domain**: Multimodal Scientific QA; Computer Vision

**Focus**: Evaluating LLMs on image-based scientific paper figure QA tasks  LLM Adapter performance 

**Keywords**: multimodal QA, scientific figures, image+text, chain-of-thought prompting

**Description**: A workshop version of SPIQA comparing 10 LLM adapter methods on the SPIQA benchmark with scientific diagram/questions. Highlights performance differences between chain-of-thought and end-to-end adapter models. 

**Task Types**: Multimodal QA

**AI Capability**: Visual reasoning, scientific figure understanding

**Metrics**: Accuracy, F1 score

**Models**: LLaVA, MiniGPT‑4, Owl‑LLM adapter variants

**Notes**: Companion to SPIQA main benchmark; compares adapter strategies using same images and QA pairs.

**Citation**:

-
  - type: article
  - id: zhong2024spiqa_llm
  - url: https://neurips.cc/virtual/2024/poster/97575
  - note: NeurIPS Poster
  - year: 2024
  - author: Zhong, Xiaoyan, Gao, Yijian, others
  - title: SPIQA‑LLM: Evaluating LLM Adapters on Scientific Figure QA
  - bibtex: |
      @article{zhong2024spiqa_llm,
        title={SPIQA‑LLM: Evaluating LLM Adapters on Scientific Figure QA},
        author={Zhong, Xiaoyan and Gao, Yijian and others},
        year={2024},
        note={NeurIPS Poster},
        url={https://neurips.cc/virtual/2024/poster/97575}
      }


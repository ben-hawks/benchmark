# MMLU (Massive Multitask Language Understanding)

**Date**: 2020-09-07

**Expiration**: 

**Valid**: yes

**Name**: MMLU  Massive Multitask Language Understanding 

**URL**: https://paperswithcode.com/dataset/mmlu

**Domain**: Multidomain

**Focus**: Academic knowledge and reasoning across 57 subjects

**Keywords**: multitask, multiple-choice, zero-shot, few-shot, knowledge probing

**Description**: Measuring Massive Multitask Language Understanding  MMLU  is a benchmark of 57  multiple-choice tasks covering elementary mathematics, US history, computer science,  law, and more, designed to evaluate a model's breadth and depth of knowledge in  zero-shot and few-shot settings. 

**Task Types**: Multiple choice

**AI Capability**: General reasoning, subject-matter understanding

**Metrics**: Accuracy

**Models**: GPT-4o, Gemini 1.5 Pro, o1, DeepSeek-R1

**Notes**: Good

**Citation**:

-
  - type: article
  - id: hendrycks2021measuring
  - url: https://arxiv.org/abs/2009.03300
  - year: 2021
  - journal: arXiv preprint arXiv:2009.03300
  - author: Hendrycks, Dan, Burns, Collin, Kadavath, Saurav, others
  - title: Measuring Massive Multitask Language Understanding
  - bibtex: |
      @article{hendrycks2021measuring,
        title={Measuring Massive Multitask Language Understanding},
        author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and others},
        journal={arXiv preprint arXiv:2009.03300},
        year={2021},
        url={https://arxiv.org/abs/2009.03300}
      }


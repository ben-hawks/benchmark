<h1 id="frontiermath">FrontierMath</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2024-11-07</p>
<p><strong>Name</strong>: FrontierMath</p>
<p><strong>Domain</strong>: Mathematics</p>
<p><strong>Focus</strong>: Challenging advanced mathematical
reasoning</p>
<p><strong>Keywords</strong>: symbolic reasoning, number theory,
algebraic geometry, category theory</p>
<p><strong>Task Types</strong>: Problem solving</p>
<p><strong>Metrics</strong>: Accuracy</p>
<p><strong>Models</strong>: unkown</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan
Chen, Alex Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain,
Anson Ho, Emily de Oliveira Santos, Olli Järviniemi, Matthew Barnett,
Robert Sandler, Matej Vrzala, Jaime Sevilla, Qiuyu Ren, Elizabeth Pratt,
Lionel Levine, Grant Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana
Grechuk, Shreepranav Varma Enugandla, and Mark Wildon. Frontiermath: a
benchmark for evaluating advanced mathematical reasoning in ai. 2024.
URL: https://arxiv.org/abs/2411.04872, arXiv:2411.04872.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{glazer2024frontiermathbenchmarkevaluatingadvanced,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Elliot Glazer and Ege Erdil and Tamay Besiroglu and Diego Chicharro and Evan Chen and Alex Gunning and Caroline Falkman Olsson and Jean-Stanislas Denain and Anson Ho and Emily de Oliveira Santos and Olli Järviniemi and Matthew Barnett and Robert Sandler and Matej Vrzala and Jaime Sevilla and Qiuyu Ren and Elizabeth Pratt and Lionel Levine and Grant Barkley and Natalie Stewart and Bogdan Grechuk and Tetiana Grechuk and Shreepranav Varma Enugandla and Mark Wildon},

eprint        = {2411.04872},

primaryclass  = {cs.AI},

title         = {FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI},

url           = {https://arxiv.org/abs/2411.04872},

year          = {2024}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> No link to code provided</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Well-specified process for asking
questions and receiving answers. No software or hardware
constraints</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> Paper and website had no link to any
dataset. It may still exist somewhere</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> by default All questions in the dataset
have a correct answer</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 2</p></li>
<li><p><strong>Reason:</strong> Displays result of leading models on the
benchmark, but none are trainable or list constraints</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> No specified way to reproduce the
reference solution</p></li>
</ul>
<p><strong>Average Rating:</strong> 1.667</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/frontiermath_radar.png"
alt="Frontiermath radar plot" /></p>

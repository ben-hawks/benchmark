<h1 id="seafloorai">SeafloorAI</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2024-12-13</p>
<p><strong>Name</strong>: SeafloorAI</p>
<p><strong>Domain</strong>: Marine Science; Vision-Language</p>
<p><strong>Focus</strong>: Large-scale vision-language dataset for
seafloor mapping and geological classification</p>
<p><strong>Keywords</strong>: sonar imagery, vision-language, seafloor
mapping, segmentation, QA</p>
<p><strong>Task Types</strong>: Image segmentation, Vision-language
QA</p>
<p><strong>Metrics</strong>: Segmentation pixel accuracy, QA
accuracy</p>
<p><strong>Models</strong>: SegFormer, ViLT-style multimodal models</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Kien X. Nguyen, Fengchun Qiao, Arthur Trembanis, and Xi Peng.
Seafloorai: a large-scale vision-language dataset for seafloor
geological survey. 2024. URL: https://arxiv.org/abs/2411.00172,
arXiv:2411.00172.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{nguyen2024seafloor,</p>
<pre><code>archiveprefix = {arXiv},

author = {Kien X. Nguyen and Fengchun Qiao and Arthur Trembanis and Xi Peng},

eprint = {2411.00172},

primaryclass = {cs.CV},

title = {SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey},

url = {https://arxiv.org/abs/2411.00172},

year=2024</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Data processing code is publicly
available, but no full benchmark framework or runnable model
implementations are provided yet.</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Tasks image segmentation and
vision-language QA are clearly defined with geospatial and multimodal
objectives well specified.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Large-scale, well-annotated sonar
imagery dataset with segmentation masks and natural language
descriptions; curated with domain experts.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Standard segmentation pixel accuracy and
QA accuracy metrics are clearly specified and appropriate for the
tasks.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Some baseline models e.g., SegFormer,
ViLT-style are mentioned, but reproducible code or pretrained weights
are not fully available yet.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Dataset description and data processing
instructions are provided, but tutorials and benchmark usage guides are
limited.</p></li>
</ul>
<p><strong>Average Rating:</strong> 4.333</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/seafloorai_radar.png"
alt="Seafloorai radar plot" /></p>

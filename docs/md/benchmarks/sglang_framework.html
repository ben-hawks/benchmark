<h1 id="sglang-framework">SGLang Framework</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2023-12-12</p>
<p><strong>Name</strong>: SGLang Framework</p>
<p><strong>Domain</strong>: LLM Vision</p>
<p><strong>Focus</strong>: Fast serving framework for LLMs and
vision-language models</p>
<p><strong>Keywords</strong>: LLM serving, vision-language,
RadixAttention, performance, JSON decoding</p>
<p><strong>Task Types</strong>: Model serving framework</p>
<p><strong>Metrics</strong>: Tokens/sec, Time-to-first-token, Throughput
gain vs baseline</p>
<p><strong>Models</strong>: LLaVA, DeepSeek, Llama</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Sun, Jeff
Huang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E.
Gonzalez, Clark Barrett, and Ying Sheng. Sglang: efficient execution of
structured language model programs. 2024. URL:
https://arxiv.org/abs/2312.07104, arXiv:2312.07104.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{zheng2024sglangefficientexecutionstructured,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},

eprint        = {2312.07104},

primaryclass  = {cs.AI},

title         = {SGLang: Efficient Execution of Structured Language Model Programs},

url           = {https://arxiv.org/abs/2312.07104},

year          = {2024}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Actively maintained and
production-deployed e.g., xAI, NVIDIA ; source code available under
Apache 2.0. Includes efficient backends RadixAttention, quantization,
batching and full serving infrastructure.</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> The framework clearly defines
performance targets, serving logic, and model integration. Input/output
expectations are consistent, but not all benchmarks are
standardized.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 2</p></li>
<li><p><strong>Reason:</strong> Does not introduce new datasets;
instead, it evaluates performance using existing model benchmarks. Only
configuration files are included.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Serving-related metrics such as
tokens/sec, time-to-first-token, and throughput gain vs.Â baselines are
well-defined and consistently applied.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Provides benchmark configs and example
integrations e.g., with LLaVA, DeepSeek , but not all models or scripts
are runnable out-of-the-box.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Strong GitHub documentation, install
guides, and benchmarks. Some advanced topics e.g., scaling, hardware
tuning could use deeper walkthroughs.</p></li>
</ul>
<p><strong>Average Rating:</strong> 3.833</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/sglang_framework_radar.png"
alt="Sglang Framework radar plot" /></p>

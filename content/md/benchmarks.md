| Date | Expiration | Valid | Name | URL | Domain | Focus | Keywords | Description | Task Types | AI Capability | Metrics | Models | Notes | Citation |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 2020-09-07 |  | yes | MMLU  Massive Multitask Language Understanding  | https://paperswithcode.com/dataset/mmlu | Multidomain | Academic knowledge and reasoning across 57 subjects | multitask, multiple-choice, zero-shot, few-shot, knowledge probing | Measuring Massive Multitask Language Understanding  MMLU  is a benchmark of 57  multiple-choice tasks covering elementary mathematics, US history, computer science,  law, and more, designed to evaluate a model's breadth and depth of knowledge in  zero-shot and few-shot settings.  | Multiple choice | General reasoning, subject-matter understanding | Accuracy | GPT-4o, Gemini 1.5 Pro, o1, DeepSeek-R1 | Good | [MMLU (Massive Multitask Language Understanding)](https://paperswithcode.com/dataset/mmlu) |
| 2023-11-20 |  | yes | GPQA Diamond | https://arxiv.org/abs/2311.12022 | Science | Graduate-level scientific reasoning | Google-proof, graduate-level, science QA, chemistry, physics | GPQA is a dataset of 448 challenging, multiple-choice questions in biology, physics, and chemistry, written by domain experts. It is “Google-proof”—experts score 65%   74% after error correction  while skilled non-experts with web access score only 34%.  State-of-the-art LLMs like GPT-4 reach around 39% accuracy.  | Multiple choice, Multi-step QA | Scientific reasoning, deep knowledge | Accuracy | o1, DeepSeek-R1 | Good | [GPQA Diamond](https://arxiv.org/abs/2311.12022) |
| 2018-03-14 |  | yes | ARC-Challenge  Advanced Reasoning Challenge  | https://allenai.org/data/arc | Science | Grade-school science with reasoning emphasis | grade-school, science QA, challenge set, reasoning | The AI2 Reasoning Challenge  ARC  Challenge set comprises 7,787 natural, grade-school science questions that retrieval-based and word co-occurrence algorithms both fail,  requiring advanced reasoning over a 14-million-sentence corpus.  | Multiple choice | Commonsense and scientific reasoning | Accuracy | GPT-4, Claude | Good | [ARC-Challenge (Advanced Reasoning Challenge)](https://allenai.org/data/arc) |
| 2025-01-24 |  | yes | Humanity's Last Exam | https://arxiv.org/abs/2501.14249 | Multidomain | Broad cross-domain academic reasoning | cross-domain, academic exam, multiple-choice, multidisciplinary | Humanity's Last Exam is a multi-domain, multiple-choice benchmark containing 2,000 questions across diverse academic disciplines, designed to evaluate LLMs' ability to reason across domains without external resources.  | Multiple choice | Cross-domain academic reasoning | Accuracy |  | Good | [Humanity's Last Exam](https://arxiv.org/abs/2501.14249) |
| 2024-11-07 |  | yes | FrontierMath | https://arxiv.org/abs/2411.04872 | Mathematics | Challenging advanced mathematical reasoning | symbolic reasoning, number theory, algebraic geometry, category theory | FrontierMath is a benchmark of hundreds of expert-vetted mathematics problems spanning number theory, real analysis, algebraic geometry, and category theory, measuring LLMs’  ability to solve problems requiring deep abstract reasoning.  | Problem solving | Symbolic and abstract mathematical reasoning | Accuracy |  | Good | [FrontierMath](https://arxiv.org/abs/2411.04872) |
| 2024-07-18 |  | yes | SciCode | https://arxiv.org/abs/2407.13168 | Scientific Programming | Scientific code generation and problem solving | code synthesis, scientific computing, programming benchmark | SciCode is a scientist-curated coding benchmark with 338 subproblems derived from 80 real research tasks across 16 scientific subfields, evaluating models on knowledge recall,  reasoning, and code synthesis for scientific computing tasks.  | Coding | Program synthesis, scientific computing | Solve rate  %  | Claude3.5-Sonnet | Good | [SciCode](https://arxiv.org/abs/2407.13168) |
| 2025-03-13 |  | yes | AIME  American Invitational Mathematics Examination  | https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions | Mathematics | Pre-college advanced problem solving | algebra, combinatorics, number theory, geometry | The AIME is a 15-question, 3-hour exam for high-school students featuring challenging short-answer math problems in algebra, number theory, geometry, and combinatorics,  assessing depth of problem-solving ability.  | Problem solving | Mathematical problem-solving and reasoning | Accuracy |  | None | [AIME (American Invitational Mathematics Examination)](https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions) |
| 2025-02-15 |  | yes | MATH-500 | https://huggingface.co/datasets/HuggingFaceH4/MATH-500 | Mathematics | Math reasoning generalization | calculus, algebra, number theory, geometry | MATH-500 is a curated subset of 500 problems from the OpenAI MATH dataset, spanning high-school to advanced levels, designed to evaluate LLMs’ mathematical reasoning and  generalization.  | Problem solving | Math reasoning and generalization | Accuracy |  | Dataset hosted on Hugging Face | [MATH-500](https://huggingface.co/datasets/HuggingFaceH4/MATH-500) |
| 2024-04-02 |  | yes | CURIE  Scientific Long-Context Understanding, Reasoning and Information Extraction  | https://arxiv.org/abs/2404.02029 | Multidomain Science | Long-context scientific reasoning | long-context, information extraction, multimodal | CURIE is a benchmark of 580 problems across six scientific disciplines—materials science, quantum computing, biology, chemistry, climate science, and astrophysics— designed to evaluate LLMs on long-context understanding, reasoning, and information  extraction in realistic scientific workflows.  | Information extraction, Reasoning, Concept tracking, Aggregation, Algebraic manipulation, Multimodal comprehension | Long-context understanding and scientific reasoning | Accuracy |  | Good | [CURIE (Scientific Long-Context Understanding, Reasoning and Information Extraction)](https://arxiv.org/abs/2404.02029) |
| 2023-01-26 |  | yes | FEABench  Finite Element Analysis Benchmark  | https://github.com/alleninstitute/feabench | Computational Engineering | FEA simulation accuracy and performance | finite element, simulation, PDE | FEABench is a suite evaluating finite element analysis tools on standardized  PDE-based simulation tasks with complex geometries and boundary conditions,  measuring both accuracy and runtime performance.  | Simulation, Performance evaluation | Numerical simulation accuracy and efficiency | Solve time, Error norm | FEniCS, deal.II | Good | [FEABench (Finite Element Analysis Benchmark)](https://github.com/alleninstitute/feabench) |
| 2024-07-12 |  | yes | SPIQA  Scientific Paper Image Question Answering  | https://arxiv.org/abs/2407.09413 | Computer Science | Multimodal QA on scientific figures | multimodal QA, figure understanding, table comprehension, chain-of-thought | SPIQA assesses AI models' ability to interpret and answer questions about figures and tables in scientific papers by integrating visual and textual modalities  with chain-of-thought reasoning.  | Question answering, Multimodal QA, Chain-of-Thought evaluation | Visual-textual reasoning in scientific contexts | Accuracy, F1 score | Chain-of-Thought models, Multimodal QA systems | Good | [SPIQA (Scientific Paper Image Question Answering)](https://arxiv.org/abs/2407.09413) |
| 2020-09-28 |  | yes | MedQA | https://arxiv.org/abs/2009.13081 | Medical Question Answering | Medical board exam QA | USMLE, diagnostic QA, medical knowledge, multilingual | MedQA is a large-scale multiple-choice dataset drawn from professional medical board exams  e.g., USMLE , testing AI systems on diagnostic and medical knowledge  questions in English and Chinese.  | Multiple choice | Medical diagnosis and knowledge retrieval | Accuracy | Neural reader, Retrieval-based QA systems | Multilingual  English, Simplified and Traditional Chinese  | [MedQA](https://arxiv.org/abs/2009.13081) |
| 2025-05-13 |  | yes | BaisBench  Biological AI Scientist Benchmark  | https://arxiv.org/abs/2505.08341 | Computational Biology | Omics-driven AI research tasks | single-cell annotation, biological QA, autonomous discovery | BaisBench evaluates AI scientists' ability to perform data-driven biological research by annotating cell types in single-cell datasets and answering MCQs derived from  biological study insights, measuring autonomous scientific discovery.  | Cell type annotation, Multiple choice | Autonomous biological research capabilities | Annotation accuracy, QA accuracy | LLM-based AI scientist agents | Underperforms human experts; aims to advance AI-driven discovery | [BaisBench (Biological AI Scientist Benchmark)](https://arxiv.org/abs/2505.08341) |
| 2023-01-26 |  | yes | MOLGEN | https://github.com/zjunlp/MolGen | Computational Chemistry | Molecular generation and optimization | SELFIES, GAN, property optimization | MolGen is a pre-trained molecular language model that generates chemically valid molecules using SELFIES and reinforcement learning, guided by chemical feedback  to optimize properties such as logP, QED, and docking score.  | Distribution learning, Goal-oriented generation | Generation of valid and optimized molecular structures | Validity%, Novelty%, QED, Docking score | MolGen | This is a model, not a benchmark | [MOLGEN](https://github.com/zjunlp/MolGen) |
| 2020-05-02 |  | yes | Open Graph Benchmark  OGB  - Biology | https://ogb.stanford.edu/docs/home/ | Graph ML | Biological graph property prediction | node prediction, link prediction, graph classification | OGB-Biology is a suite of large-scale biological network datasets  protein-protein interaction, drug-target, etc.  with standardized splits and evaluation protocols  for node, link, and graph property prediction tasks.  | Node property prediction, Link property prediction, Graph property prediction | Scalability and generalization in graph ML for biology | Accuracy, ROC-AUC | GCN, GraphSAGE, GAT | Community-driven updates | [Open Graph Benchmark (OGB) - Biology](https://ogb.stanford.edu/docs/home/) |
| 2011-10-01 |  | yes | Materials Project | https://materialsproject.org/ | Materials Science | DFT-based property prediction | DFT, materials genome, high-throughput | The Materials Project provides an open-access database of computed properties for inorganic materials via high-throughput density functional theory  DFT , accelerating  materials discovery.  | Property prediction | Prediction of inorganic material properties | MAE, R² | Automatminer, Crystal Graph Neural Networks | Core component of the Materials Genome Initiative | [Materials Project](https://materialsproject.org/) |
| 2020-10-20 |  | yes | OCP  Open Catalyst Project  | https://opencatalystproject.org/ | Chemistry; Materials Science | Catalyst adsorption energy prediction | DFT relaxations, adsorption energy, graph neural networks | The Open Catalyst Project  OC20 and OC22  provides DFT-calculated catalyst-adsorbate  relaxation datasets, challenging ML models to predict energies and forces for  renewable energy applications.  | Energy prediction, Force prediction | Prediction of adsorption energies and forces | MAE  energy , MAE  force  | CGCNN, SchNet, DimeNet++, GemNet-OC | Public leaderboards; active community development | [OCP (Open Catalyst Project)](https://opencatalystproject.org/) |
| 2023-06-20 |  | yes | JARVIS-Leaderboard | https://arxiv.org/abs/2306.11688 | Materials Science; Benchmarking | Comparative evaluation of materials design methods | leaderboards, materials methods, simulation | JARVIS-Leaderboard is a community-driven platform benchmarking AI, electronic structure, force-fields, quantum computing, and experimental methods across hundreds of materials science tasks.  | Method benchmarking, Leaderboard ranking | Performance comparison across diverse materials design methods | MAE, RMSE, Accuracy |  | 1,281 contributions across 274 benchmarks | [JARVIS-Leaderboard](https://arxiv.org/abs/2306.11688) |
| 2022-02-22 |  | yes | Quantum Computing Benchmarks  QML  | https://github.com/XanaduAI/qml-benchmarks, https://pennylane.ai/datasets/collection/qml-benchmarks | Quantum Computing | Quantum algorithm performance evaluation | quantum circuits, state preparation, error correction | A suite of benchmarks evaluating quantum hardware and algorithms on tasks such as state  preparation, circuit optimization, and error correction across multiple platforms.  | Circuit benchmarking, State classification | Quantum algorithm performance and fidelity | Fidelity, Success probability | IBM Q, IonQ, AQT@LBNL | Hardware-agnostic, application-level metrics. The citation may not be correct. | Quantum Computing Benchmarks (QML) [(Link 1)](https://github.com/XanaduAI/qml-benchmarks) [(Link 2)](https://pennylane.ai/datasets/collection/qml-benchmarks) |
| 2024-10-01 |  | yes | CFDBench  Fluid Dynamics  | https://arxiv.org/abs/2310.05963 | Fluid Dynamics; Scientific ML | Neural operator surrogate modeling | neural operators, CFD, FNO, DeepONet | CFDBench provides large-scale CFD data for four canonical fluid flow problems,  assessing neural operators' ability to generalize to unseen PDE parameters and domains.  | Surrogate modeling | Generalization of neural operators for PDEs | L2 error, MAE | FNO, DeepONet, U-Net | 302K frames across 739 cases | [CFDBench (Fluid Dynamics)](https://arxiv.org/abs/2310.05963) |
| None |  | yes | SatImgNet | None | Remote Sensing | Satellite imagery classification | land-use, zero-shot, multi-task | SATIN  sometimes referred to as SatImgNet  is a multi-task metadataset of 27 satellite imagery classification datasets evaluating zero-shot transfer of vision-language models across diverse remote sensing tasks.  | Image classification | Zero-shot land-use classification | Accuracy |  | Public leaderboard available | [SatImgNet](None) |
| 2023-07-19 |  | yes | ClimateLearn | https://arxiv.org/abs/2307.01909 | Climate Science; Forecasting | ML for weather and climate modeling | medium-range forecasting, ERA5, data-driven | ClimateLearn provides standardized datasets and evaluation protocols for machine  learning models in medium-range weather and climate forecasting using ERA5 reanalysis.  | Forecasting | Global weather prediction  3-5 days  | RMSE, Anomaly correlation | CNN baselines, ResNet variants | Includes physical and ML baselines. Appears to be the same as the SatImgNet entry | [ClimateLearn](https://arxiv.org/abs/2307.01909) |
| 2022-06-09 |  | yes | BIG-Bench  Beyond the Imitation Game Benchmark  | https://github.com/google/BIG-bench | NLP; AI Evaluation | Diverse reasoning and generalization tasks | few-shot, multi-task, bias analysis | BIG-Bench is a collaborative suite of 204 tasks designed to probe LLMs' reasoning,  knowledge, and bias across diverse domains and difficulty levels beyond simple imitation.  | Few-shot evaluation, Multi-task evaluation | Reasoning and generalization across diverse tasks | Accuracy, Task-specific metrics | GPT-3, Dense Transformers, Sparse Transformers | Human baselines included | [BIG-Bench (Beyond the Imitation Game Benchmark)](https://github.com/google/BIG-bench) |
| 2019-11-20 |  | yes | CommonSenseQA | https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge | NLP; Commonsense | Commonsense question answering | ConceptNet, multiple-choice, adversarial | CommonsenseQA is a challenging multiple-choice QA dataset built from ConceptNet, requiring models to apply commonsense knowledge to select the correct answer  among five choices.  | Multiple choice | Commonsense reasoning and knowledge integration | Accuracy | BERT-large, RoBERTa, GPT-3 | Baseline 56%, human 89% | [CommonSenseQA](https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge) |
| 2019-07-24 |  | yes | Winogrande | https://leaderboard.allenai.org/winogrande/submissions/public | NLP; Commonsense | Winograd Schema-style pronoun resolution | adversarial, pronoun resolution | WinoGrande is a large-scale adversarial dataset of 44,000 Winograd Schema-style  questions with reduced bias using AFLite, serving as both a benchmark and transfer  learning resource.  | Pronoun resolution | Robust commonsense reasoning | Accuracy, AUC | RoBERTa, BERT, GPT-2 | Human ~94% | [Winogrande](https://leaderboard.allenai.org/winogrande/submissions/public) |
| 2024-05-01 |  | yes | Jet Classification | https://github.com/fastmachinelearning/fastml-science/tree/main/jet-classify | Particle Physics | Real-time classification of particle jets using HL-LHC simulation features | classification, real-time ML, jet tagging, QKeras | This benchmark evaluates ML models for real-time classification of particle jets using  high-level features derived from simulated LHC data. It includes both full-precision  and quantized models optimized for FPGA deployment.  | Classification | Real-time inference, model compression performance | Accuracy, AUC | Keras DNN, QKeras quantized DNN | Includes both float and quantized models using QKeras | [Jet Classification](https://github.com/fastmachinelearning/fastml-science/tree/main/jet-classify) |
| 2024-05-01 |  | yes | Irregular Sensor Data Compression | https://github.com/fastmachinelearning/fastml-science/tree/main/sensor-data-compression | Particle Physics | Real-time compression of sparse sensor data with autoencoders | compression, autoencoder, sparse data, irregular sampling | This benchmark addresses lossy compression of irregularly sampled sensor data from  particle detectors using real-time autoencoder architectures, targeting latency-critical  applications in physics experiments.  | Compression | Reconstruction quality, compression efficiency | MSE, Compression ratio | Autoencoder, Quantized autoencoder | Based on synthetic but realistic physics sensor data | [Irregular Sensor Data Compression](https://github.com/fastmachinelearning/fastml-science/tree/main/sensor-data-compression) |
| 2024-05-01 |  | yes | Beam Control | https://github.com/fastmachinelearning/fastml-science/tree/main/beam-control | Accelerators and Magnets | Reinforcement learning control of accelerator beam position | RL, beam stabilization, control systems, simulation | Beam Control explores real-time reinforcement learning strategies for maintaining  stable beam trajectories in particle accelerators. The benchmark is based on the  BOOSTR environment for accelerator simulation.  | Control | Policy performance in simulated accelerator control | Stability, Control loss | DDPG, PPO  planned  | Environment defined, baseline RL implementation is in progress | [Beam Control](https://github.com/fastmachinelearning/fastml-science/tree/main/beam-control) |
| 2024-07-08 |  | yes | Ultrafast jet classification at the HL-LHC | https://arxiv.org/pdf/2402.01876 | Particle Physics | FPGA-optimized real-time jet origin classification at the HL-LHC | jet classification, FPGA, quantization-aware training, Deep Sets, Interaction Networks | Demonstrates three ML models  MLP, Deep Sets, Interaction Networks  optimized for FPGA deployment with O 100 ns  inference using quantized models and hls4ml, targeting real-time jet tagging in the L1 trigger environment at the high-luminosity LHC. Data is available on Zenodo DOI:10.5281/zenodo.3602260. :contentReference oaicite:1 {index=1}  | Classification | Real-time inference under FPGA constraints | Accuracy, Latency, Resource utilization | MLP, Deep Sets, Interaction Network | Uses quantization-aware training; hardware synthesis evaluated via hls4ml | [Ultrafast jet classification at the HL-LHC](https://arxiv.org/pdf/2402.01876) |
| 2024-10-15 |  | yes | Quench detection | https://indico.cern.ch/event/1387540/contributions/6153618/attachments/2948441/5182077/fast_ml_magnets_2024_final.pdf | Accelerators and Magnets | Real-time detection of superconducting magnet quenches using ML | quench detection, autoencoder, anomaly detection, real-time | Exploration of real-time quench detection using unsupervised and RL approaches, combining multi-modal sensor data  BPM, power supply, acoustic , operating on kHz-MHz streams with anomaly detection and frequency-domain features. :contentReference oaicite:2 {index=2}  | Anomaly detection, Quench localization | Real-time anomaly detection with multi-modal sensors | ROC‑AUC, Detection latency | Autoencoder, RL agents  in development  | Precursor detection in progress; multi-modal and dynamic weighting methods | [Quench detection](https://indico.cern.ch/event/1387540/contributions/6153618/attachments/2948441/5182077/fast_ml_magnets_2024_final.pdf) |
| 2024-10-15 |  | yes | DUNE | https://indico.fnal.gov/event/66520/contributions/301423/attachments/182439/250508/fast_ml_dunedaq_sonic_10_15_24.pdf | Particle Physics | Real-time ML for DUNE DAQ time-series data | DUNE, time-series, real-time, trigger | Applying real-time ML methods to time-series data from DUNE detectors, exploring trigger-level anomaly detection and event selection with low latency constraints.  | Trigger selection, Time-series anomaly detection | Low-latency event detection | Detection efficiency, Latency | CNN, LSTM  planned  | Prototype models demonstrated on SONIC platform | [DUNE](https://indico.fnal.gov/event/66520/contributions/301423/attachments/182439/250508/fast_ml_dunedaq_sonic_10_15_24.pdf) |
| 2025-01-08 |  | yes | Intelligent experiments through real-time AI | https://arxiv.org/pdf/2501.04845 | Instrumentation and Detectors; Nuclear Physics; Particle Physics | Real-time FPGA-based triggering and detector control for sPHENIX and future EIC | FPGA, Graph Neural Network, hls4ml, real-time inference, detector control | Resaerch and Development demonstrator for real-time processing of high-rate tracking data from the sPHENIX detector  RHIC  and future EIC systems. Uses GNNs with hls4ml for FPGA-based trigger generation to identify rare events  heavy flavor, DIS electrons  within 10 µs latency. Demonstrated improved accuracy and latency on Alveo/FELIX platforms.  | Trigger classification, Detector control, Real-time inference | Low-latency GNN inference on FPGA | Accuracy  charm and beauty detection , Latency  µs , Resource utilization  LUT/FF/BRAM/DSP  | Bipartite Graph Network with Set Transformers  BGN-ST , GarNet  edge-classifier  | Achieved ~97.4% accuracy for beauty decay triggers; sub-10 µs latency on Alveo U280; hit-based FPGA design via hls4ml and FlowGNN. | [Intelligent experiments through real-time AI](https://arxiv.org/pdf/2501.04845) |
| 2025-01-09 |  | yes | Neural Architecture Codesign for Fast Physics Applications | https://arxiv.org/abs/2501.05515 | Physics; Materials Science; Particle Physics | Automated neural architecture search and hardware-efficient model codesign for fast physics applications | neural architecture search, FPGA deployment, quantization, pruning, hls4ml | Introduces a two-stage neural architecture codesign  NAC  pipeline combining global and local search, quantization-aware training, and pruning to design efficient models for fast Bragg peak finding and jet classification, synthesized for FPGA deployment with hls4ml. Achieves >30× reduction in BOPs and sub-100 ns inference latency on FPGA.  | Classification, Peak finding | Hardware-aware model optimization; low-latency inference | Accuracy, Latency, Resource utilization | NAC-based BraggNN, NAC-optimized Deep Sets  jet  | Demonstrated two case studies  materials science, HEP ; pipeline and code open-sourced. | [Neural Architecture Codesign for Fast Physics Applications](https://arxiv.org/abs/2501.05515) |
| 2024-06-24 |  | yes | Smart Pixels for LHC | https://arxiv.org/abs/2406.14860 | Particle Physics; Instrumentation and Detectors | On-sensor, in-pixel ML filtering for high-rate LHC pixel detectors | smart pixel, on-sensor inference, data reduction, trigger | Presents a 256×256-pixel ROIC in 28 nm CMOS with embedded 2-layer NN for cluster filtering at 25 ns, achieving 54-75% data reduction while maintaining noise and latency constraints. Prototype consumes ~300 µW/pixel and operates in combinatorial digital logic.  | Image Classification, Data filtering | On-chip, low-power inference; data reduction | Data rejection rate, Power per pixel | 2-layer pixel NN | Prototype in CMOS 28 nm; proof-of-concept for Phase III pixel upgrades. | [Smart Pixels for LHC](https://arxiv.org/abs/2406.14860) |
| 2023-10-03 |  | yes | HEDM  BraggNN  | https://arxiv.org/abs/2008.08198 | Material Science | Fast Bragg peak analysis using deep learning in diffraction microscopy | BraggNN, diffraction, peak finding, HEDM | Uses BraggNN, a deep neural network, for rapid Bragg peak localization in high-energy diffraction microscopy, achieving ~13× speedup compared to Voigt-based methods while maintaining sub-pixel accuracy.  | Peak detection | High-throughput peak localization | Localization accuracy, Inference time | BraggNN | Enables real-time HEDM workflows; basis for NAC case study. | [HEDM (BraggNN)](https://arxiv.org/abs/2008.08198) |
| 2023-12-03 |  | yes | 4D‑STEM | https://openreview.net/pdf?id=7yt3N0o0W9 | Material Science | Real-time ML for scanning transmission electron microscopy | 4D-STEM, electron microscopy, real-time, image processing | Proposes ML methods for real-time analysis of 4D scanning transmission electron microscopy datasets; framework details in progress.  | Image Classification, Streamed data inference | Real-time large-scale microscopy inference | Classification accuracy, Throughput | CNN models  prototype  | In-progress; model design under development. | [4D‑STEM](https://openreview.net/pdf?id=7yt3N0o0W9) |
| 2023-12-05 |  | yes | In‑Situ High‑Speed Computer Vision | https://arxiv.org/abs/2312.00128 | Fusion/Plasma | Real-time image classification for in-situ plasma diagnostics | plasma, in-situ vision, real-time ML | Applies low-latency CNN models for image classification of plasma diagnostics streams; supports deployment on embedded platforms.  | Image Classification | Real-time diagnostic inference | Accuracy, FPS | CNN | Embedded/deployment details in progress. | [In‑Situ High‑Speed Computer Vision](https://arxiv.org/abs/2312.00128) |
| 2020-01-01 |  | yes | BenchCouncil AIBench | https://www.benchcouncil.org/AIBench/ | General | End-to-end AI benchmarking across micro, component, and application levels | benchmarking, AI systems, application-level evaluation | AIBench is a comprehensive benchmark suite that evaluates AI workloads at different levels  micro, component, application  across hardware systems—covering image generation, object detection, translation, recommendation, video prediction, etc. | Training, Inference, End-to-end AI workloads | System-level AI workload performance | Throughput, Latency, Accuracy | ResNet, BERT, GANs, Recommendation systems | Covers scenario-distilling, micro, component, and end-to-end benchmarks. | [BenchCouncil AIBench](https://www.benchcouncil.org/AIBench/) |
| 2020-01-01 |  | yes | BenchCouncil BigDataBench | https://www.benchcouncil.org/BigDataBench/ | General | Big data and AI benchmarking across structured, semi-structured, and unstructured data workloads | big data, AI benchmarking, data analytics | BigDataBench provides benchmarks for evaluating big data and AI workloads with realistic datasets  13 sources  and pipelines across analytics, graph, warehouse, NoSQL, streaming, and AI. | Data preprocessing, Inference, End-to-end data pipelines | Data processing and AI model inference performance at scale | Data throughput, Latency, Accuracy | CNN, LSTM, SVM, XGBoost | Built on eight data motifs; provides Hadoop, Spark, Flink, MPI implementations. | [BenchCouncil BigDataBench](https://www.benchcouncil.org/BigDataBench/) |
| 2021-10-20 |  | yes | MLPerf HPC | https://github.com/mlcommons/hpc | Cosmology, Climate, Protein Structure, Catalysis | Scientific ML training and inference on HPC systems | HPC, training, inference, scientific ML | MLPerf HPC introduces scientific model benchmarks  e.g., CosmoFlow, DeepCAM  aimed at large-scale HPC evaluation with >10× performance scaling through system-level optimizations. | Training, Inference | Scaling efficiency, training time, model accuracy on HPC | Training time, Accuracy, GPU utilization | CosmoFlow, DeepCAM, OpenCatalyst | Shared framework with MLCommons Science; reference implementations included. | [MLPerf HPC](https://github.com/mlcommons/hpc) |
| 2023-06-01 |  | yes | MLCommons Science | https://github.com/mlcommons/science | Earthquake, Satellite Image, Drug Discovery, Electron Microscope, CFD | AI benchmarks for scientific applications including time-series, imaging, and simulation | science AI, benchmark, MLCommons, HPC | MLCommons Science assembles benchmark tasks with datasets, targets, and implementations across earthquake forecasting, satellite imagery, drug screening, electron microscopy, and CFD to drive scientific ML reproducibility. | Time-series analysis, Image classification, Simulation surrogate modeling | Inference accuracy, simulation speed-up, generalization | MAE, Accuracy, Speedup vs simulation | CNN, GNN, Transformer | Joint national-lab effort under Apache‑2.0 license. | [MLCommons Science](https://github.com/mlcommons/science) |
| 2021-07-05 |  | yes | LHC New Physics Dataset | https://arxiv.org/pdf/2107.02157 | Particle Physics; Real-time Triggering | Real-time LHC event filtering for anomaly detection using proton collision data | anomaly detection, proton collision, real-time inference, event filtering, unsupervised ML | A dataset of proton-proton collision events emulating a 40 MHz real-time data stream from LHC detectors, pre-filtered on electron or muon presence. Designed for unsupervised new-physics detection algorithms under latency/bandwidth constraints. | Anomaly detection, Event classification | Unsupervised signal detection under latency and bandwidth constraints | ROC-AUC, Detection efficiency | Autoencoder, Variational autoencoder, Isolation forest | Includes electron/muon-filtered background and black-box signal benchmarks; 1M events per black box. | [LHC New Physics Dataset](https://arxiv.org/pdf/2107.02157) |
| 2023-07-17 |  | yes | MLCommons Medical AI | https://github.com/mlcommons/medical | Healthcare; Medical AI | Federated benchmarking and evaluation of medical AI models across diverse real-world clinical data | medical AI, federated evaluation, privacy-preserving, fairness, healthcare benchmarks | The MLCommons Medical AI working group develops benchmarks, best practices, and platforms  MedPerf, GaNDLF, COFE  to accelerate robust, privacy‐preserving AI development for healthcare. MedPerf enables federated testing of clinical models on diverse datasets, improving generalizability and equity while keeping data onsite :contentReference oaicite:1 {index=1}.  | Federated evaluation, Model validation | Clinical accuracy, fairness, generalizability, privacy compliance | ROC AUC, Accuracy, Fairness metrics | MedPerf-validated CNNs, GaNDLF workflows | Open-source platform under Apache‑2.0; used across 20+ institutions and hospitals :contentReference oaicite:2 {index=2}. | [MLCommons Medical AI](https://github.com/mlcommons/medical) |
| 2024-10-28 |  | yes | CaloChallenge 2022 | http://arxiv.org/abs/2410.21611 | LHC Calorimeter; Particle Physics | Fast generative-model-based calorimeter shower simulation evaluation | calorimeter simulation, generative models, surrogate modeling, LHC, fast simulation | The Fast Calorimeter Simulation Challenge 2022 assessed 31 generative‐model submissions  VAEs, GANs, Flows, Diffusion  on four calorimeter shower datasets; benchmarking shower quality, generation speed, and model complexity :contentReference oaicite:3 {index=3}.  | Surrogate modeling | Simulation fidelity, speed, efficiency | Histogram similarity, Classifier AUC, Generation latency | VAE variants, GAN variants, Normalizing flows, Diffusion models | The most comprehensive survey to date on ML-based calorimeter simulation; 31 submissions over different dataset sizes. | [CaloChallenge 2022](http://arxiv.org/abs/2410.21611) |
| ongoing |  | yes | Papers With Code  SOTA Platform  | https://paperswithcode.com/sota | General ML; All domains | Open platform tracking state-of-the-art results, benchmarks, and implementations across ML tasks and papers | leaderboard, benchmarking, reproducibility, open-source | Papers With Code  PWC  aggregates benchmark suites, tasks, and code across ML research: 12,423 benchmarks, 5,358 unique tasks, and 154,766 papers with code links. It tracks SOTA metrics and fosters reproducibility.  | Multiple  Classification, Detection, NLP, etc.  | Model performance across tasks  accuracy, F1, BLEU, etc.  | Task-specific  Accuracy, F1, BLEU, etc.  | All published models with code | Community-driven open platform; automatic data extraction and versioning. | [Papers With Code (SOTA Platform)](https://paperswithcode.com/sota) |
| 2022-01-01 |  | yes | Codabench | https://www.codabench.org/ | General ML; Multiple | Open-source platform for organizing reproducible AI benchmarks and competitions | benchmark platform, code submission, competitions, meta-benchmark | Codabench  successor to CodaLab  is a flexible, easy‑to‑use, reproducible API platform for hosting AI benchmarks and code‑submission challenges. It supports custom scoring, inverted benchmarks, and scalable public or private queues :contentReference oaicite:1 {index=1}.  | Multiple | Model reproducibility, performance across datasets | Submission count, Leaderboard ranking, Task-specific metrics | Arbitrary code submissions | Hosts 51 public competitions, ~26 k users, 177 k submissions :contentReference oaicite:2 {index=2} | [Codabench](https://www.codabench.org/) |
| 2021-09-27 |  | yes | Sabath  SBI‑FAIR  | https://sbi-fair.github.io/docs/software/sabath/ | Systems; Metadata | FAIR metadata framework for ML-driven surrogate workflows in HPC systems | meta‑benchmark, metadata, HPC, surrogate modeling | Sabath is a metadata framework from the SBI‑FAIR group  UTK, Argonne, Virginia  facilitating FAIR-compliant benchmarking and surrogate execution logging across HPC systems :contentReference oaicite:3 {index=3}.  | Systems benchmarking | Metadata tracking, reproducible HPC workflows | Metadata completeness, FAIR compliance | N/A | Developed by PI Piotr Luszczek at UTK; integrates with MiniWeatherML, AutoPhaseNN, Cosmoflow, etc. :contentReference oaicite:4 {index=4} | [Sabath (SBI‑FAIR)](https://sbi-fair.github.io/docs/software/sabath/) |
| 2022-10-13 |  | yes | PDEBench | https://github.com/pdebench/PDEBench | CFD; Weather Modeling | Benchmark suite for ML-based surrogates solving time-dependent PDEs | PDEs, CFD, scientific ML, surrogate modeling, NeurIPS | PDEBench offers forward/inverse PDE tasks with large ready‑to‑use datasets and baselines  FNO, U‑Net, PINN , packaged via a unified API. It won the SimTech Best Paper Award 2023 :contentReference oaicite:5 {index=5}.  | Supervised Learning | Time-dependent PDE modeling; physical accuracy | RMSE, boundary RMSE, Fourier RMSE | FNO, U‑Net, PINN, Gradient‑Based inverse methods | Datasets hosted on DaRUS  DOI:10.18419/darus‑2986 ; contact maintainers by email :contentReference oaicite:6 {index=6} | [PDEBench](https://github.com/pdebench/PDEBench) |
| 2024-12-03 |  | yes | The Well | https://polymathic-ai.org/the_well/ | biological systems, fluid dynamics, acoustic scattering, astrophysical MHD | Foundation model + surrogate dataset spanning 16 physical simulation domains | surrogate modeling, foundation model, physics simulations, spatiotemporal dynamics | A 15 TB collection of ML-ready physics simulation datasets  HDF5 , covering 16 domains—from biology to astrophysical magnetohydrodynamic simulations—with unified API and metadata. Ideal for training surrogate and foundation models on scientific data. :contentReference oaicite:1 {index=1}  | Supervised Learning | Surrogate modeling, physics-based prediction | Dataset size, Domain breadth | FNO baselines, U‑Net baselines | Includes unified API and dataset metadata; see 2025 NeurIPS paper for full benchmark details. Size: 15 TB. :contentReference oaicite:2 {index=2} | [The Well](https://polymathic-ai.org/the_well/) |
| 2024-10-31 |  | yes | LLM-Inference-Bench | https://github.com/argonne-lcf/LLM-Inference-Bench | LLM; HPC/inference | Hardware performance benchmarking of LLMs on AI accelerators | LLM, inference benchmarking, GPU, accelerator, throughput | A suite evaluating inference performance of LLMs  LLaMA, Mistral, Qwen  across diverse accelerators  NVIDIA, AMD, Intel, SambaNova  and frameworks  vLLM, DeepSpeed‑MII, etc. , with an interactive dashboard and per-platform metrics. :contentReference oaicite:3 {index=3}  | Inference Benchmarking | Inference throughput, latency, hardware utilization | Token throughput  tok/s , Latency, Framework-hardware mix performance | LLaMA-2‑7B, LLaMA-2‑70B, Mistral‑7B, Qwen‑7B | Licensed under BSD‑3, maintained by Argonne; supports GPUs and accelerators. :contentReference oaicite:4 {index=4} | [LLM-Inference-Bench](https://github.com/argonne-lcf/LLM-Inference-Bench) |
| 2023-12-12 |  | yes | SGLang Framework | https://github.com/sgl-project/sglang/tree/main/benchmark | LLM Vision | Fast serving framework for LLMs and vision-language models | LLM serving, vision-language, RadixAttention, performance, JSON decoding | A high-performance open-source serving framework combining efficient backend runtime  RadixAttention, batching, quantization  and expressive frontend language, boosting LLM/VLM inference throughput up to ~3x over alternatives. :contentReference oaicite:5 {index=5}  | Model serving framework | Serving throughput, JSON/task-specific latency | Tokens/sec, Time-to-first-token, Throughput gain vs baseline | LLaVA, DeepSeek, Llama | Deployed in production  xAI, NVIDIA, Google Cloud ; v0.4.8 release June 2025. :contentReference oaicite:6 {index=6} | [SGLang Framework](https://github.com/sgl-project/sglang/tree/main/benchmark) |
| 2023-09-12 |  | yes | vLLM Inference and Serving Engine | https://github.com/vllm-project/vllm/tree/main/benchmarks | LLM; HPC/inference | High-throughput, memory-efficient inference and serving engine for LLMs | LLM inference, PagedAttention, CUDA graph, streaming API, quantization | vLLM is a fast, high-throughput, memory-efficient inference and serving engine for large language models,  featuring PagedAttention, continuous batching, and support for quantized and pipelined model execution.  Benchmarks compare it to TensorRT-LLM, SGLang, and others. :contentReference oaicite:1 {index=1}  | Inference Benchmarking | Throughput, latency, memory efficiency | Tokens/sec, Time to First Token  TTFT , Memory footprint | LLaMA, Mixtral, FlashAttention-based models | Incubated by LF AI and Data; achieves up to 24× throughput over HuggingFace Transformers :contentReference oaicite:2 {index=2} | [vLLM Inference and Serving Engine](https://github.com/vllm-project/vllm/tree/main/benchmarks) |
| 2022-06-22 |  | yes | vLLM Performance Dashboard | https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/ | LLM; HPC/inference | Interactive dashboard showing inference performance of vLLM | Dashboard, Throughput visualization, Latency analysis, Metric tracking | A live visual dashboard for vLLM showcasing throughput, latency, and other inference metrics across models and hardware configurations.  | Performance visualization | Throughput, latency, hardware utilization | Tokens/sec, TTFT, Memory usage | LLaMA-2, Mistral, Qwen | Built using ObservableHQ; integrates live data from vLLM benchmarks. | [vLLM Performance Dashboard](https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/) |
| 2022-04-01 |  | yes | Nixtla NeuralForecast | https://github.com/Nixtla/neuralforecast | Time-series forecasting; General ML | High-performance neural forecasting library with >30 models | time-series, neural forecasting, NBEATS, NHITS, TFT, probabilistic forecasting, usability | NeuralForecast offers scalable, user-friendly implementations of over 30 neural forecasting models  NBEATS, NHITS, TFT, DeepAR, etc. , emphasizing quality, usability, interpretability, and performance. :contentReference oaicite:3 {index=3}  | Time-series forecasting | Forecast accuracy, interpretability, speed | RMSE, MAPE, CRPS | NBEATS, NHITS, TFT, DeepAR | AutoModel supports hyperparameter tuning and distributed execution via Ray and Optuna. Fi­rst official NHITS implementation. :contentReference oaicite:4 {index=4} | [Nixtla NeuralForecast](https://github.com/Nixtla/neuralforecast) |
| 2023-06-01 |  | yes | Nixtla Neural Forecast NHITS | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Official NHITS implementation for long-horizon time series forecasting | NHITS, long-horizon forecasting, neural interpolation, time-series | NHITS  Neural Hierarchical Interpolation for Time Series  is a state-of-the-art model that improved accuracy by ~25% and reduced compute by 50× compared to Transformer baselines, using hierarchical interpolation and multi-rate sampling :contentReference oaicite:1 {index=1}.  | Time-series forecasting | Accuracy, compute efficiency for long series | RMSE, MAPE | NHITS | Official implementation in NeuralForecast, included since its AAAI 2023 release. | [Nixtla Neural Forecast NHITS](https://github.com/Nixtla/neuralforecast) |
| 2023-10-03 |  | yes | Nixtla Neural Forecast TimeLLM | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Reprogramming LLMs for time series forecasting | Time-LLM, language model, time-series, reprogramming | Time‑LLM uses reprogramming layers to adapt frozen LLMs for time series forecasting, treating forecasting as a language task :contentReference oaicite:2 {index=2}.  | Time-series forecasting | Model reuse via LLM, few-shot forecasting | RMSE, MAPE | Time‑LLM | Fully open-source; transforms forecasting using LLM text reconstruction. | [Nixtla Neural Forecast TimeLLM](https://github.com/Nixtla/neuralforecast) |
| 2023-10-05 |  | yes | Nixtla Neural Forecast TimeGPT | https://github.com/Nixtla/neuralforecast | Time-series; General ML | Time-series foundation model "TimeGPT" for forecasting and anomaly detection | TimeGPT, foundation model, time-series, generative model | TimeGPT is a transformer-based generative pretrained model on 100B+ time series data for zero-shot forecasting and anomaly detection via API :contentReference oaicite:3 {index=3}.  | Time-series forecasting, Anomaly detection | Zero-shot forecasting, anomaly detection | RMSE, Anomaly detection metrics | TimeGPT | Offered via Nixtla API and Azure Studio; enterprise-grade support available. | [Nixtla Neural Forecast TimeGPT](https://github.com/Nixtla/neuralforecast) |
| 2025-03-03 |  | yes | HDR ML Anomaly Challenge  Gravitational Waves  | https://www.codabench.org/competitions/2626/ | Astrophysics; Time-series | Detecting anomalous gravitational-wave signals from LIGO/Virgo datasets | anomaly detection, gravitational waves, astrophysics, time-series | A benchmark for detecting anomalous transient gravitational-wave signals, including “unknown-unknowns,” using preprocessed LIGO time-series at 4096 Hz. Competitors submit inference models on Codabench for continuous 50 ms segments from dual interferometers. :contentReference oaicite:1 {index=1}  | Anomaly detection | Novel event detection in physical signals | ROC‑AUC, Precision/Recall | Deep latent CNNs, Autoencoders | NSF HDR A3D3 sponsored; prize pool and starter kit provided on Codabench. :contentReference oaicite:2 {index=2} | [HDR ML Anomaly Challenge (Gravitational Waves)](https://www.codabench.org/competitions/2626/) |
| 2025-03-03 |  | yes | HDR ML Anomaly Challenge  Butterfly  | https://www.codabench.org/competitions/3764/ | Genomics; Image/CV | Detecting hybrid butterflies via image anomaly detection in genomic-informed dataset | anomaly detection, computer vision, genomics, butterfly hybrids | Image-based challenge for detecting butterfly hybrids in microscopy-driven species data. Participants evaluate models on Codabench using image segmentation/classification. :contentReference oaicite:3 {index=3}  | Anomaly detection | Hybrid detection in biological systems | Classification accuracy, F1 score | CNN-based detectors | Hybrid detection benchmarks hosted on Codabench. :contentReference oaicite:4 {index=4} | [HDR ML Anomaly Challenge (Butterfly)](https://www.codabench.org/competitions/3764/) |
| 2025-03-03 |  | yes | HDR ML Anomaly Challenge  Sea Level Rise  | https://www.codabench.org/competitions/3223/ | Climate Science; Time-series, Image/CV | Detecting anomalous sea-level rise and flooding events via time-series and satellite imagery | anomaly detection, climate science, sea-level rise, time-series, remote sensing | A challenge combining North Atlantic sea-level time-series and satellite imagery to detect flooding anomalies. Models submitted via Codabench. :contentReference oaicite:5 {index=5}  | Anomaly detection | Detection of environmental anomalies | ROC‑AUC, Precision/Recall | CNNs, RNNs, Transformers | Sponsored by NSF HDR; integrates sensor and satellite data. :contentReference oaicite:6 {index=6} | [HDR ML Anomaly Challenge (Sea Level Rise)](https://www.codabench.org/competitions/3223/) |
| 2025-01-24 |  | yes | Single Qubit Readout on QICK System | https://github.com/fastmachinelearning/ml-quantum-readout | Quantum Computing | Real-time single-qubit state classification using FPGA firmware | qubit readout, hls4ml, FPGA, QICK | Implements real-time ML models for single-qubit readout on the Quantum Instrumentation Control Kit  QICK , using hls4ml to deploy quantized neural networks on RFSoC FPGAs. Offers high-fidelity, low-latency quantum state discrimination. :contentReference oaicite:0 {index=0}    | Classification | Single-shot fidelity, inference latency | Accuracy, Latency | hls4ml quantized NN | Achieves ~96% fidelity with ~32 ns latency and low FPGA resource utilization. :contentReference oaicite:1 {index=1} | [Single Qubit Readout on QICK System](https://github.com/fastmachinelearning/ml-quantum-readout) |
| 2023-11-20 |  | yes | GPQA: A Graduate-Level Google-Proof Question and Answer Benchmark | https://arxiv.org/abs/2311.12022 | Science  Biology, Physics, Chemistry  | Graduate-level, expert-validated multiple-choice questions hard even with web access | Google-proof, multiple-choice, expert reasoning, science QA | Contains 448 challenging questions written by domain experts, with expert accuracy at 65%  74% discounting clear errors  and non-experts reaching just 34%. GPT‑4 baseline scores ~39%—designed for scalable oversight evaluation. :contentReference oaicite:2 {index=2}    | Multiple choice | Scientific reasoning, knowledge probing | Accuracy | GPT‑4 baseline | “Google-proof”; supports oversight research. | [GPQA: A Graduate-Level Google-Proof Question and Answer Benchmark](https://arxiv.org/abs/2311.12022) |
| 2024-12-13 |  | yes | SeafloorAI | https://neurips.cc/virtual/2024/poster/97432 | Marine Science; Vision-Language | Large-scale vision-language dataset for seafloor mapping and geological classification | sonar imagery, vision-language, seafloor mapping, segmentation, QA | A first-of-its-kind dataset covering 17,300 km² of seafloor with 696K sonar images, 827K segmentation masks, and 696K natural-language descriptions plus ~7M QA pairs—designed for both vision and language-based ML models in marine science :contentReference oaicite:1 {index=1}.  | Image segmentation, Vision-language QA | Geospatial understanding, multimodal reasoning | Segmentation pixel accuracy, QA accuracy | SegFormer, ViLT-style multimodal models | Data processing code publicly available, covering five geological layers; curated with marine scientists :contentReference oaicite:2 {index=2}. | [SeafloorAI](https://neurips.cc/virtual/2024/poster/97432) |
| 2024-12-13 |  | yes | SuperCon3D | https://neurips.cc/virtual/2024/poster/97553 | Materials Science; Superconductivity | Dataset and models for predicting and generating high‑Tc superconductors using 3D crystal structures | superconductivity, crystal structures, equivariant GNN, generative models | SuperCon3D introduces 3D crystal structures with associated critical temperatures  Tc  and two deep-learning models: SODNet  equivariant graph model  and DiffCSP‑SC  diffusion generator  designed to screen and synthesize high‑Tc candidates :contentReference oaicite:3 {index=3}.  | Regression  Tc prediction , Generative modeling | Structure-to-property prediction, structure generation | MAE  Tc , Validity of generated structures | SODNet, DiffCSP‑SC | Demonstrates advantage of combining ordered and disordered structural data in model design :contentReference oaicite:4 {index=4}. | [SuperCon3D](https://neurips.cc/virtual/2024/poster/97553) |
| 2024-12-13 |  | yes | GeSS | https://neurips.cc/virtual/2024/poster/97816 | Scientific ML; Geometric Deep Learning | Benchmark suite evaluating geometric deep learning models under real-world distribution shifts | geometric deep learning, distribution shift, OOD robustness, scientific applications | GeSS provides 30 benchmark scenarios across particle physics, materials science, and biochemistry, evaluating 3 GDL backbones and 11 algorithms under covariate, concept, and conditional shifts, with varied OOD access :contentReference oaicite:5 {index=5}.  | Classification, Regression | OOD performance in scientific settings | Accuracy, RMSE, OOD robustness delta | GCN, EGNN, DimeNet++ | Includes no-OOD, unlabeled-OOD, and few-label scenarios :contentReference oaicite:6 {index=6}. | [GeSS](https://neurips.cc/virtual/2024/poster/97816) |
| 2024-12-13 |  | yes | Vocal Call Locator  VCL  | https://neurips.cc/virtual/2024/poster/97470 | Neuroscience; Bioacoustics | Benchmarking sound-source localization of rodent vocalizations from multi-channel audio | source localization, bioacoustics, time-series, SSL | The first large-scale benchmark  767K sounds across 9 conditions  for localizing rodent vocal calls using synchronized audio and video in standard lab environments, enabling systematic evaluation of sound-source localization algorithms in bioacoustics :contentReference oaicite:1 {index=1}.  | Sound source localization | Source localization accuracy in bioacoustic settings | Localization error  cm , Recall/Precision | CNN-based SSL models | Dataset spans real, simulated, and mixed audio; supports benchmarking across data types :contentReference oaicite:2 {index=2}. | [Vocal Call Locator (VCL)](https://neurips.cc/virtual/2024/poster/97470) |
| 2024-12-13 |  | yes | MassSpecGym | https://neurips.cc/virtual/2024/poster/97823 | Cheminformatics; Molecular Discovery | Benchmark suite for discovery and identification of molecules via MS/MS | mass spectrometry, molecular structure, de novo generation, retrieval, dataset | MassSpecGym curates the largest public MS/MS dataset with three standardized tasks—de novo structure generation, molecule retrieval, and spectrum simulation—using challenging generalization splits to propel ML-driven molecule discovery :contentReference oaicite:3 {index=3}.  | De novo generation, Retrieval, Simulation | Molecular identification and generation from spectral data | Structure accuracy, Retrieval precision, Simulation MSE | Graph-based generative models, Retrieval baselines | Dataset~>1M spectra; open-source GitHub repo; widely cited as a go-to benchmark for MS/MS tasks :contentReference oaicite:4 {index=4}. | [MassSpecGym](https://neurips.cc/virtual/2024/poster/97823) |
| 2024-12-13 |  | yes | Urban Data Layer  UDL  | https://neurips.cc/virtual/2024/poster/97837 | Urban Computing; Data Engineering | Unified data pipeline for multi-modal urban science research | data pipeline, urban science, multi-modal, benchmark | UrbanDataLayer standardizes heterogeneous urban data formats and provides pipelines for tasks like air quality prediction and land-use classification, enabling the rapid creation of multi-modal urban benchmarks :contentReference oaicite:5 {index=5}.  | Prediction, Classification | Multi-modal urban inference, standardization | Task-specific accuracy or RMSE | Baseline regression/classification pipelines | Source code available on GitHub  SJTU-CILAB/udl ; promotes reusable urban-science foundation models :contentReference oaicite:6 {index=6}. | [Urban Data Layer (UDL)](https://neurips.cc/virtual/2024/poster/97837) |
| 2024-12-13 |  | yes | Delta Squared‑DFT | https://neurips.cc/virtual/2024/poster/97788 | Computational Chemistry; Materials Science | Benchmarking machine-learning corrections to DFT using Delta Squared-trained models for reaction energies | density functional theory, Delta Squared‑ML correction, reaction energetics, quantum chemistry | Introduces the Delta Squared‑ML paradigm—using ML corrections to DFT to predict reaction energies with accuracy comparable to CCSD T , while training on small CC datasets. Evaluated across 10 reaction datasets covering organic and organometallic transformations.  | Regression | High-accuracy energy prediction, DFT correction | Mean Absolute Error  eV , Energy ranking accuracy | Delta Squared‑ML correction networks, Kernel ridge regression | Demonstrates CC-level accuracy with ~1% of high-level data. Benchmarks publicly included for reproducibility. | [Delta Squared‑DFT](https://neurips.cc/virtual/2024/poster/97788) |
| 2024-12-13 |  | yes | LLMs for Crop Science | https://neurips.cc/virtual/2024/poster/97570 | Agricultural Science; NLP | Evaluating LLMs on crop trait QA and textual inference tasks with domain-specific prompts | crop science, prompt engineering, domain adaptation, question answering | Establishes a benchmark of 3,500 expert-annotated prompts and QA pairs covering crop traits, growth stages, and environmental interactions. Tests GPT-style LLMs on accuracy and domain reasoning using in-context, chain-of-thought, and retrieval-augmented prompts.  | Question Answering, Inference | Scientific knowledge, crop reasoning | Accuracy, F1 score | GPT-4, LLaMA-2‑13B, T5‑XXL | Includes examples with retrieval-augmented and chain-of-thought prompt templates; supports few-shot adaptation. | [LLMs for Crop Science](https://neurips.cc/virtual/2024/poster/97570) |
| 2024-12-13 |  | yes | SPIQA  LLM  | https://neurips.cc/virtual/2024/poster/97575 | Multimodal Scientific QA; Computer Vision | Evaluating LLMs on image-based scientific paper figure QA tasks  LLM Adapter performance  | multimodal QA, scientific figures, image+text, chain-of-thought prompting | A workshop version of SPIQA comparing 10 LLM adapter methods on the SPIQA benchmark with scientific diagram/questions. Highlights performance differences between chain-of-thought and end-to-end adapter models.  | Multimodal QA | Visual reasoning, scientific figure understanding | Accuracy, F1 score | LLaVA, MiniGPT‑4, Owl‑LLM adapter variants | Companion to SPIQA main benchmark; compares adapter strategies using same images and QA pairs. | [SPIQA (LLM)](https://neurips.cc/virtual/2024/poster/97575) |

<h1 id="spiqa-llm">SPIQA (LLM)</h1>
<p><strong>Date</strong>: 2024-12-13</p>
<p><strong>Name</strong>: SPIQA LLM</p>
<p><strong>Domain</strong>: Multimodal Scientific QA; Computer
Vision</p>
<p><strong>Focus</strong>: Evaluating LLMs on image-based scientific
paper figure QA tasks LLM Adapter performance</p>
<p><strong>Keywords</strong>: multimodal QA, scientific figures,
image+text, chain-of-thought prompting</p>
<p><strong>Task Types</strong>: Multimodal QA</p>
<p><strong>Metrics</strong>: Accuracy, F1 score</p>
<p><strong>Models</strong>: LLaVA, MiniGPT-4, Owl-LLM adapter
variants</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Shraman Pramanick, Rama Chellappa, and Subhashini Venugopalan.
Spiqa: a dataset for multimodal question answering on scientific papers.
2025. URL: https://arxiv.org/abs/2407.09413, arXiv:2407.09413.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{pramanick2025spiqadatasetmultimodalquestion,</p>
<pre><code>title={SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers}, 

author={Shraman Pramanick and Rama Chellappa and Subhashini Venugopalan},

year={2025},

eprint={2407.09413},

archivePrefix={arXiv},

primaryClass={cs.CL},

url={https://arxiv.org/abs/2407.09413}, </code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Well-documented codebase available on
Github</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 3.5</p></li>
<li><p><strong>Reason:</strong> Task of QA over scientific figures is
sufficient but not fully formalized in input/output terms. No hawrdware
constraints.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Full dataset available on Hugging Face
with train/test/valid splits.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Reports accuracy and F1; fair but no
visual reasoning-specific metric.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> 10 LLM adapter baselines; results
included without constraints.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Full paper available</p></li>
</ul>
<p><strong>Average Rating:</strong> 4.417</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/spiqa_llm_radar.png"
alt="Spiqa Llm radar plot" /></p>

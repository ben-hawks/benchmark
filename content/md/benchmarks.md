 | date | name | domain | focus | keywords | task_types | metrics | models | cite | 
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
2024-05-01 | Jet Classification | Particle Physics | Real-time classification of particle jets using HL-LHC simulation features | classification, real-time ML, jet tagging, QKeras | Classification | Accuracy, AUC | Keras DNN, QKeras quantized DNN | [^hawks2022fastml] @article{hawks2022fastml,   title={Fast Machine Learning for Science: Benchmarks and Dataset},   author={Hawks, Ben and Tran, Nhan and others},   year={2022},   url={https://arxiv.org/abs/2207.07958} }  | 
2024-05-01 | Irregular Sensor Data Compression | Particle Physics | Real-time compression of sparse sensor data with autoencoders | compression, autoencoder, sparse data, irregular sampling | Compression | MSE, Compression ratio | Autoencoder, Quantized autoencoder | @article{hawks2022fastml2,   title={Fast Machine Learning for Science: Benchmarks and Dataset},   author={Hawks, Ben and Tran, Nhan and others},   year={2022},   url={https://arxiv.org/abs/2207.07958} }  | 
2024-05-01 | Beam Control | Accelerators and Magnets | Reinforcement learning control of accelerator beam position | RL, beam stabilization, control systems, simulation | Control | Stability, Control loss | DDPG, PPO (planned) | @article{hawks2022fastml3,   title={Fast Machine Learning for Science: Benchmarks and Dataset},   author={Hawks, Ben and Tran, Nhan and others},   year={2022},   url={https://arxiv.org/abs/2207.07958} } , @article{wang2021booster,   title={BOOSTR: A Dataset for Accelerator Control Systems},   author={Wang, Qizhi and others},   year={2021},   url={https://arxiv.org/abs/2101.08359} }  | 
2024-07-08 | Ultrafast jet classification at the HL-LHC | Particle Physics | FPGA-optimized real-time jet origin classification at the HL-LHC | jet classification, FPGA, quantization-aware training, Deep Sets, Interaction Networks | Classification | Accuracy, Latency, Resource utilization | MLP, Deep Sets, Interaction Network |  | 
2024-10-15 | Quench detection | Accelerators and Magnets | Real-time detection of superconducting magnet quenches using ML | quench detection, autoencoder, anomaly detection, real-time | Anomaly detection, Quench localization | ROC-AUC, Detection latency | Autoencoder, RL agents (in development) |  | 
2024-10-15 | DUNE | Particle Physics | Real-time ML for DUNE DAQ time-series data | DUNE, time-series, real-time, trigger | Trigger selection, Time-series anomaly detection | Detection efficiency, Latency | CNN, LSTM (planned) |  | 
2025-01-08 | Intelligent experiments through real-time AI | Instrumentation and Detectors; Nuclear Physics; Particle Physics | Real-time FPGA-based triggering and detector control for sPHENIX and future EIC | FPGA, Graph Neural Network, hls4ml, real-time inference, detector control | Trigger classification, Detector control, Real-time inference | Accuracy (charm and beauty detection), Latency (Âµs), Resource utilization (LUT/FF/BRAM/DSP) | Bipartite Graph Network with Set Transformers (BGN-ST), GarNet (edge-classifier) | @article{kvapil2025intelligent,   title={Intelligent experiments through real-time AI: Fast Data Processing and Autonomous Detector Control for sPHENIX and future EIC detectors},   author={Kvapil, Jakub and Borca-Tasciuc, Giorgian and ... Tran, Nhan and others},   year={2025},   url={https://arxiv.org/abs/2501.04845} }  | 
2025-01-09 | Neural Architecture Codesign for Fast Physics Applications | Physics; Materials Science; Particle Physics | Automated neural architecture search and hardware-efficient model codesign for fast physics applications | neural architecture search, FPGA deployment, quantization, pruning, hls4ml | Classification, Peak finding | Accuracy, Latency, Resource utilization | NAC-based BraggNN, NAC-optimized Deep Sets (jet) | @article{weitz2025nacph,   title={Neural Architecture Codesign for Fast Physics Applications},   author={Weitz, Jason and Demler, Dmitri and McDermott, Luke and Tran, Nhan and Duarte, Javier},   year={2025},   url={https://arxiv.org/abs/2501.05515} }  | 
2024-06-24 | Smart Pixels for LHC | Particle Physics; Instrumentation and Detectors | On-sensor, in-pixel ML filtering for high-rate LHC pixel detectors | smart pixel, on-sensor inference, data reduction, trigger | Image Classification, Data filtering | Data rejection rate, Power per pixel | 2-layer pixel NN | @article{parpillon2024smartpixels,   title={Smart Pixels: In-pixel AI for on-sensor data filtering},   author={Parpillon, Benjamin and ... and Tran, Nhan},   year={2024},   url={https://arxiv.org/abs/2406.14860} }  | 
2023-10-03 | HEDM BraggNN | Material Science | Fast Bragg peak analysis using deep learning in diffraction microscopy | BraggNN, diffraction, peak finding, HEDM | Peak detection | Localization accuracy, Inference time | BraggNN | @article{xiao2020braggnn,   title={BraggNN: Fast X-ray Bragg peak analysis using deep learning},   author={Xiao, Yu and ...},   year={2020},   url={https://arxiv.org/abs/2008.08198} }  | 
2023-12-03 | 4D-STEM | Material Science | Real-time ML for scanning transmission electron microscopy | 4D-STEM, electron microscopy, real-time, image processing | Image Classification, Streamed data inference | Classification accuracy, Throughput | CNN models (prototype) | @inproceedings{anonymous2023_4dstem,   title={4D-STEM: Real-Time ML for Electron Microscopy},   author={Anonymous},   year={2023},   url={https://openreview.net/pdf?id=7yt3N0o0W9} }  | 
2023-12-05 | In-Situ High-Speed Computer Vision | Fusion/Plasma | Real-time image classification for in-situ plasma diagnostics | plasma, in-situ vision, real-time ML | Image Classification | Accuracy, FPS | CNN | @article{smith2023insitu,   title={In-Situ High-Speed Computer Vision for Plasma Diagnostics},   author={Smith, John and Doe, Jane},   year={2023},   url={https://arxiv.org/abs/2312.00128} }  | 
2020-01-01 | BenchCouncil AIBench | General | End-to-end AI benchmarking across micro, component, and application levels | benchmarking, AI systems, application-level evaluation | Training, Inference, End-to-end AI workloads | Throughput, Latency, Accuracy | ResNet, BERT, GANs, Recommendation systems | @inproceedings{gao2020aibench,   title={AIBench: An Industry Standard Internet Service AI Benchmark Suite},   author={Gao, Wanling and Zhan, Jianfeng and others},   year={2020},   url={https://arxiv.org/abs/1908.08998} }  | 
2020-01-01 | BenchCouncil BigDataBench | General | Big data and AI benchmarking across structured, semi-structured, and unstructured data workloads | big data, AI benchmarking, data analytics | Data preprocessing, Inference, End-to-end data pipelines | Data throughput, Latency, Accuracy | CNN, LSTM, SVM, XGBoost | @article{gao2018bigdatabench,   title={BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite},   author={Gao, Wanling and Zhan, Jianfeng and others},   year={2018},   url={https://arxiv.org/abs/1802.08254} }  | 
2021-10-20 | MLPerf HPC | Cosmology, Climate, Protein Structure, Catalysis | Scientific ML training and inference on HPC systems | HPC, training, inference, scientific ML | Training, Inference | Training time, Accuracy, GPU utilization | CosmoFlow, DeepCAM, OpenCatalyst | @inproceedings{farrell2021mlperf,   title={MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning on HPC Systems},   author={Farrell, Steven and Emani, Murali and others},   year={2021},   url={https://arxiv.org/abs/2110.11466} }  | 
2023-06-01 | MLCommons Science | Earthquake, Satellite Image, Drug Discovery, Electron Microscope, CFD | AI benchmarks for scientific applications including time-series, imaging, and simulation | science AI, benchmark, MLCommons, HPC | Time-series analysis, Image classification, Simulation surrogate modeling | MAE, Accuracy, Speedup vs simulation | CNN, GNN, Transformer | @misc{mlcommons_science2023,   title={MLCommons Science Working Group Benchmarks},   author={MLCommons Science Working Group},   year={2023},   url={https://github.com/mlcommons/science} }  | 
2021-07-05 | LHC New Physics Dataset | Particle Physics; Real-time Triggering | Real-time LHC event filtering for anomaly detection using proton collision data | anomaly detection, proton collision, real-time inference, event filtering, unsupervised ML | Anomaly detection, Event classification | ROC-AUC, Detection efficiency | Autoencoder, Variational autoencoder, Isolation forest | @article{govorkova2022lhcnewphysics,   title={LHC physics dataset for unsupervised New Physics detection at 40 MHz},   author={Govorkova, Ekaterina and Puljak, Ema and Pierini, Maurizio and others},   journal={Scientific Data},   year={2022},   doi={10.6084/m9.figshare.5046389},   url={https://doi.org/10.5281/zenodo.5046389} }  | 
2023-07-17 | MLCommons Medical AI | Healthcare; Medical AI | Federated benchmarking and evaluation of medical AI models across diverse real-world clinical data | medical AI, federated evaluation, privacy-preserving, fairness, healthcare benchmarks | Federated evaluation, Model validation | ROC AUC, Accuracy, Fairness metrics | MedPerf-validated CNNs, GaNDLF workflows | @article{karargyris2023federated,   title={Federated benchmarking of medical artificial intelligence with MedPerf},   author={Karargyris, Alex and Sheller, Micah J and others},   journal={Nature Machine Intelligence},   year={2023},   url={https://www.nature.com/articles/s42256-023-00652-2} }  | 
2024-10-28 | CaloChallenge 2022 | LHC Calorimeter; Particle Physics | Fast generative-model-based calorimeter shower simulation evaluation | calorimeter simulation, generative models, surrogate modeling, LHC, fast simulation | Surrogate modeling | Histogram similarity, Classifier AUC, Generation latency | VAE variants, GAN variants, Normalizing flows, Diffusion models | @article{krause2024calochallenge,   title={CaloChallenge 2022: A Community Challenge for Fast Calorimeter Simulation},   author={Krause, Claudius and Nachman, Benjamin and others},   year={2024},   url={https://arxiv.org/abs/2410.21611} }  | 
ongoing | Papers With Code- SOTA Platform | General ML; All domains | Open platform tracking state-of-the-art results, benchmarks, and implementations across ML tasks and papers | leaderboard, benchmarking, reproducibility, open-source | Multiple (Classification, Detection, NLP, etc.) | Task-specific (Accuracy, F1, BLEU, etc.) | All published models with code | @misc{pwc2025,   title={Papers With Code: Open machine learning benchmarks and leaderboards},   author={Papers With Code},   year={2025},   url={https://paperswithcode.com} }  | 
2022-01-01 | Codabench | General ML; Multiple | Open-source platform for organizing reproducible AI benchmarks and competitions | benchmark platform, code submission, competitions, meta-benchmark | Multiple | Submission count, Leaderboard ranking, Task-specific metrics | Arbitrary code submissions | @article{xu2021codabench,   title={Codabench: Flexible, easy-to-use, and reproducible meta-benchmark platform},   author={Xu, Zhen and Escalera, Sergio and others},   journal={Patterns},   volume={3},   number={7},   pages={100543},   year={2022},   doi={10.1016/j.patter.2022.100543} }  | 
2021-09-27 | Sabath - SBI-FAIR | Systems; Metadata | FAIR metadata framework for ML-driven surrogate workflows in HPC systems | meta-benchmark, metadata, HPC, surrogate modeling | Systems benchmarking | Metadata completeness, FAIR compliance | N/A | @techreport{luszczek2021sabath,   title={SABATH: FAIR Metadata Technology for Surrogate Benchmarks},   author={Luszczek, Piotr and others},   year={2021},   institution={University of Tennessee} }  | 
2022-10-13 | PDEBench | CFD; Weather Modeling | Benchmark suite for ML-based surrogates solving time-dependent PDEs | PDEs, CFD, scientific ML, surrogate modeling, NeurIPS | Supervised Learning | RMSE, boundary RMSE, Fourier RMSE | FNO, U-Net, PINN, Gradient-Based inverse methods | @inproceedings{takamoto2022pdebench,   author={Takamoto, Makoto and Praditia, Timothy and others},   title={PDEBench: An Extensive Benchmark for Scientific Machine Learning},   booktitle={NeurIPS Datasets and Benchmarks Track},   year={2022},   url={https://arxiv.org/abs/2210.07182} }  | 
2024-12-03 | The Well | biological systems, fluid dynamics, acoustic scattering, astrophysical MHD | Foundation model + surrogate dataset spanning 16 physical simulation domains | surrogate modeling, foundation model, physics simulations, spatiotemporal dynamics | Supervised Learning | Dataset size, Domain breadth | FNO baselines, U-Net baselines | @article{ohana2024well,   title={The well: a large-scale collection of diverse physics simulations for machine learning},   author={Ohana, Ruben and McCabe, Michael and Meyer, Lucas and others},   journal={NeurIPS},   volume={37},   pages={44989--45037},   year={2024} }  | 
2024-10-31 | LLM-Inference-Bench | LLM; HPC/inference | Hardware performance benchmarking of LLMs on AI accelerators | LLM, inference benchmarking, GPU, accelerator, throughput | Inference Benchmarking | Token throughput (tok/s), Latency, Framework-hardware mix performance | LLaMA-2-7B, LLaMA-2-70B, Mistral-7B, Qwen-7B | @article{chitty2024llm,   title={LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators},   author={Chitty-Venkata, Krishna Teja and Raskar, Siddhisanket and others},   journal={arXiv preprint arXiv:2411.00136},   year={2024} }  | 
2023-12-12 | SGLang Framework | LLM Vision | Fast serving framework for LLMs and vision-language models | LLM serving, vision-language, RadixAttention, performance, JSON decoding | Model serving framework | Tokens/sec, Time-to-first-token, Throughput gain vs baseline | LLaVA, DeepSeek, Llama | @article{zheng2023sglang,   title={SGLang: Efficient Execution of Structured Language Model Programs},   author={Zheng, Lianmin and Yin, Liangsheng and others},   year={2023},   url={https://arxiv.org/abs/2312.07104} }  | 
2023-09-12 | vLLM Inference and Serving Engine | LLM; HPC/inference | High-throughput, memory-efficient inference and serving engine for LLMs | LLM inference, PagedAttention, CUDA graph, streaming API, quantization | Inference Benchmarking | Tokens/sec, Time to First Token (TTFT), Memory footprint | LLaMA, Mixtral, FlashAttention-based models | @inproceedings{kwon2023efficient,   title={Efficient Memory Management for Large Language Model Serving with PagedAttention},   author={Woosuk Kwon and others},   booktitle={SOSP 2023},   year={2023} }  | 
2022-06-22 | vLLM Performance Dashboard | LLM; HPC/inference | Interactive dashboard showing inference performance of vLLM | Dashboard, Throughput visualization, Latency analysis, Metric tracking | Performance visualization | Tokens/sec, TTFT, Memory usage | LLaMA-2, Mistral, Qwen | @misc{mo2024vllm_dashboard,   title={vLLM Performance Dashboard},   author={Mo, Simon},   year={2024},   url={https://simon-mo-workspace.observablehq.cloud/vllm-dashboard-v0/} }  | 
2022-04-01 | Nixtla NeuralForecast | Time-series forecasting; General ML | High-performance neural forecasting library with >30 models | time-series, neural forecasting, NBEATS, NHITS, TFT, probabilistic forecasting, usability | Time-series forecasting | RMSE, MAPE, CRPS | NBEATS, NHITS, TFT, DeepAR | @misc{olivares2022library_neuralforecast,   author={Olivares, Kin G. and ChallÃº, Cristian and others},   title={NeuralForecast: User friendly state-of-the-art neural forecasting models},   year={2022},   howpublished={{PyCon} US},   url={https://github.com/Nixtla/neuralforecast} }  | 
2023-06-01 | Nixtla Neural Forecast NHITS | Time-series; General ML | Official NHITS implementation for long-horizon time series forecasting | NHITS, long-horizon forecasting, neural interpolation, time-series | Time-series forecasting | RMSE, MAPE | NHITS | @inproceedings{challu2023nhits,   title={NHITS: Neural Hierarchical Interpolation for Time Series Forecasting},   author={Challu, Cristian and Olivares, Kin G. and others},   booktitle={AAAI 2023},   year={2023} }  | 
2023-10-03 | Nixtla Neural Forecast TimeLLM | Time-series; General ML | Reprogramming LLMs for time series forecasting | Time-LLM, language model, time-series, reprogramming | Time-series forecasting | RMSE, MAPE | Time-LLM | @article{jin2023time,   title={Time-LLM: Time Series Forecasting by Reprogramming Large Language Models},   author={Jin, Ming and Wang, Shiyu and others},   journal={arXiv preprint arXiv:2310.01728},   year={2023} }  | 
2023-10-05 | Nixtla Neural Forecast TimeGPT | Time-series; General ML | Time-series foundation model "TimeGPT" for forecasting and anomaly detection | TimeGPT, foundation model, time-series, generative model | Time-series forecasting, Anomaly detection | RMSE, Anomaly detection metrics | TimeGPT | @article{garza2023timegpt,   title={TimeGPT-1: A Foundation Model for Time Series},   author={Garza, Azul and Challu, Cristian and others},   year={2023},   url={https://arxiv.org/abs/2310.03589} }  | 
2025-03-03 | HDR ML Anomaly Challenge- Gravitational Waves | Astrophysics; Time-series | Detecting anomalous gravitational-wave signals from LIGO/Virgo datasets | anomaly detection, gravitational waves, astrophysics, time-series | Anomaly detection | ROC-AUC, Precision/Recall | Deep latent CNNs, Autoencoders | @article{campolongo2025hdranomaly2,   title={Building Machine Learning Challenges for Anomaly Detection in Science},   author={Campolongo, Elizabeth G. and others},   year={2025},   url={https://arxiv.org/abs/2503.02112} }  | 
2025-03-03 | HDR ML Anomaly Challenge- Butterfly | Genomics; Image/CV | Detecting hybrid butterflies via image anomaly detection in genomic-informed dataset | anomaly detection, computer vision, genomics, butterfly hybrids | Anomaly detection | Classification accuracy, F1 score | CNN-based detectors | @article{campolongo2025hdranomaly,   title={Building Machine Learning Challenges for Anomaly Detection in Science},   author={Campolongo, Elizabeth G. and others},   year={2025},   url={https://arxiv.org/abs/2503.02112} }  | 
2025-03-03 | HDR ML Anomaly Challenge, Sea Level Rise | Climate Science; Time-series, Image/CV | Detecting anomalous sea-level rise and flooding events via time-series and satellite imagery | anomaly detection, climate science, sea-level rise, time-series, remote sensing | Anomaly detection | ROC-AUC, Precision/Recall | CNNs, RNNs, Transformers | @article{campolongo2025hdranomaly3,   title={Building Machine Learning Challenges for Anomaly Detection in Science},   author={Campolongo, Elizabeth G. and others},   year={2025},   url={https://arxiv.org/abs/2503.02112} }  | 
2025-01-24 | Single Qubit Readout on QICK System | Quantum Computing | Real-time single-qubit state classification using FPGA firmware | qubit readout, hls4ml, FPGA, QICK | Classification | Accuracy, Latency | hls4ml quantized NN | @article{diguglielmo2025endtoend,   title={End-to-end workflow for machine learning-based qubit readout with QICK and hls4ml},   author={Di Guglielmo, Giuseppe and Campos, Javier and others},   year={2025},   url={https://arxiv.org/abs/2501.14663} }  | 
2023-11-20 | GPQA: A Graduate Level Google Proof Question and Answer Benchmark | Science (Biology, Physics, Chemistry) | Graduate-level, expert-validated multiple-choice questions hard even with web access | Google-proof, multiple-choice, expert reasoning, science QA | Multiple choice | Accuracy | GPT-4 baseline | @article{rein2023gpqa,   title={GPQA: A Graduate-Level Google-Proof Q and A Benchmark},   author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and others},   year={2023},   url={https://arxiv.org/abs/2311.12022} }  | 
2024-12-13 | SeafloorAI | Marine Science; Vision-Language | Large-scale vision-language dataset for seafloor mapping and geological classification | sonar imagery, vision-language, seafloor mapping, segmentation, QA | Image segmentation, Vision-language QA | Segmentation pixel accuracy, QA accuracy | SegFormer, ViLT-style multimodal models | @article{nguyen2024seafloorai,   title={SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey},   author={Nguyen, Kien X. and Qiao, Fengchun and others},   year={2024},   url={https://arxiv.org/abs/2411.00172} }  | 
2024-12-13 | SuperCon3D | Materials Science; Superconductivity | Dataset and models for predicting and generating high-Tc superconductors using 3D crystal structures | superconductivity, crystal structures, equivariant GNN, generative models | Regression (Tc prediction), Generative modeling | MAE (Tc), Validity of generated structures | SODNet, DiffCSP-SC | @article{zhuang2024supercon3d,   title={SuperCon3D: Learning Superconductivity from Ordered and Disordered Material Structures},   author={Zuo, Zhong and others},   year={2024},   note={NeurIPS Poster} }  | 
2024-12-13 | GeSS | Scientific ML; Geometric Deep Learning | Benchmark suite evaluating geometric deep learning models under real-world distribution shifts | geometric deep learning, distribution shift, OOD robustness, scientific applications | Classification, Regression | Accuracy, RMSE, OOD robustness delta | GCN, EGNN, DimeNet++ | @article{zou2024gess,   title={GeSS: Benchmarking Geometric Deep Learning under Scientific Applications with Distribution Shifts},   author={Zou, Deyu and Liu, Shikun and others},   year={2024},   note={NeurIPS Poster} }  | 
2024-12-13 | Vocal Call Locator | Neuroscience; Bioacoustics | Benchmarking sound-source localization of rodent vocalizations from multi-channel audio | source localization, bioacoustics, time-series, SSL | Sound source localization | Localization error (cm), Recall/Precision | CNN-based SSL models | @article{peterson2024vcl,   title={Vocal Call Locator Benchmark for localizing rodent vocalizations},   author={Peterson, Ralph and Tanelus, Aramis and others},   year={2024},   note={NeurIPS Poster},   url={https://neurips.cc/virtual/2024/poster/97470} }  | 
2024-12-13 | MassSpecGym | Cheminformatics; Molecular Discovery | Benchmark suite for discovery and identification of molecules via MS/MS | mass spectrometry, molecular structure, de novo generation, retrieval, dataset | De novo generation, Retrieval, Simulation | Structure accuracy, Retrieval precision, Simulation MSE | Graph-based generative models, Retrieval baselines | @article{bushuiev2024massspecgym,   title={MassSpecGym: A benchmark for the discovery and identification of molecules},   author={Bushuiev, Roman and Bushuiev, Anton and others},   year={2024},   note={NeurIPS Spotlight Poster},   url={https://neurips.cc/virtual/2024/poster/97823} }  | 
2024-12-13 | Urban Data Layer | Urban Computing; Data Engineering | Unified data pipeline for multi-modal urban science research | data pipeline, urban science, multi-modal, benchmark | Prediction, Classification | Task-specific accuracy or RMSE | Baseline regression/classification pipelines | @article{wang2024urbandatalayer,   title={UrbanDataLayer: A unified data pipeline for urban science},   author={Wang, Yiheng and Wang, Tianyu and others},   year={2024},   note={NeurIPS Poster},   url={https://neurips.cc/virtual/2024/poster/97837} }  | 
2024-12-13 | Delta Squared-DFT | Computational Chemistry; Materials Science | Benchmarking machine-learning corrections to DFT using Delta Squared-trained models for reaction energies | density functional theory, Delta Squared-ML correction, reaction energetics, quantum chemistry | Regression | Mean Absolute Error (eV), Energy ranking accuracy | Delta Squared-ML correction networks, Kernel ridge regression | @article{liu2024delta2dft,   title={Delta Squared-DFT: Machine-Learning Corrected Density Functional Theory for Reaction Energetics},   author={Liu, Wei and Chen, Rong and others},   year={2024},   note={NeurIPS Poster},   url={https://neurips.cc/virtual/2024/poster/97788} }  | 
2024-12-13 | LLMs for Crop Science | Agricultural Science; NLP | Evaluating LLMs on crop trait QA and textual inference tasks with domain-specific prompts | crop science, prompt engineering, domain adaptation, question answering | Question Answering, Inference | Accuracy, F1 score | GPT-4, LLaMA-2-13B, T5-XXL | @article{patel2024llmcropsci,   title={Large Language Models for Crop Science: Benchmarking Domain Reasoning and QA},   author={Patel, Deepak and Zhao, Lan and others},   year={2024},   note={NeurIPS Poster},   url={https://neurips.cc/virtual/2024/poster/97570} }  | 
2024-12-13 | SPIQA LLM | Multimodal Scientific QA; Computer Vision | Evaluating LLMs on image-based scientific paper figure QA tasks (LLM Adapter performance) | multimodal QA, scientific figures, image+text, chain-of-thought prompting | Multimodal QA | Accuracy, F1 score | LLaVA, MiniGPT-4, Owl-LLM adapter variants | @article{zhong2024spiqa_llm,   title={SPIQA-LLM: Evaluating LLM Adapters on Scientific Figure QA},   author={Zhong, Xiaoyan and Gao, Yijian and others},   year={2024},   note={NeurIPS Poster},   url={https://neurips.cc/virtual/2024/poster/97575} }  | 

[^hawks2022fastml]: @article{hawks2022fastml,   title={Fast Machine Learning for Science: Benchmarks and Dataset},   author={Hawks, Ben and Tran, Nhan and others},   year={2022},   url={https://arxiv.org/abs/2207.07958} }

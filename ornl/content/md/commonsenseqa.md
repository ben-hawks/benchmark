# CommonSenseQA

**Date**: 2019-11-20

**Expiration**: 

**Valid**: yes

**Name**: CommonSenseQA

**URL**: https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge

**Domain**: NLP; Commonsense

**Focus**: Commonsense question answering

**Keyword**: ConceptNet, multiple-choice, adversarial

**Description**: CommonsenseQA is a challenging multiple-choice QA dataset built from ConceptNet, requiring models to apply commonsense knowledge to select the correct answer  among five choices. 

**Task Types**: Multiple choice

**AI Capability**: Commonsense reasoning and knowledge integration

**Metrics**: Accuracy

**Models**: BERT-large, RoBERTa, GPT-3

**Notes**: Baseline 56%, human 89%

**Citation**:

-
  - type: misc
  - id: talmor2019commonsenseqaquestionansweringchallenge
  - bibtex: |
      @misc{talmor2019commonsenseqaquestionansweringchallenge, title={CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge}, author={Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant}, year={2019}, eprint={1811.00937}, archivePrefix={arXiv}, primaryClass={cs.CL}, url={https://arxiv.org/abs/1811.00937}, }


# CommonSenseQA

**Date**: 2019-11-20

**Expiration**: 

**Valid**: yes

**Name**: CommonSenseQA

**URL**: https://paperswithcode.com/paper/commonsenseqa-a-question-answering-challenge

**Domain**: NLP; Commonsense

**Focus**: Commonsense question answering

**Keywords**: ConceptNet, multiple-choice, adversarial

**Description**: CommonsenseQA is a challenging multiple-choice QA dataset built from ConceptNet, requiring models to apply commonsense knowledge to select the correct answer  among five choices. 

**Task Types**: Multiple choice

**AI Capability**: Commonsense reasoning and knowledge integration

**Metrics**: Accuracy

**Models**: BERT-large, RoBERTa, GPT-3

**Notes**: Baseline 56%, human 89%

**Citation**:

-
  - type: misc
  - id: talmor2019commonsenseqaquestionansweringchallenge
  - url: https://arxiv.org/abs/1811.00937
  - primaryclass: cs.CL
  - archiveprefix: arXiv
  - eprint: 1811.00937
  - year: 2019
  - author: Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant
  - title: CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge
  - bibtex: |
      @misc{talmor2019commonsenseqaquestionansweringchallenge,
        title={CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge}, 
        author={Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},
        year={2019},
        eprint={1811.00937},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/1811.00937}, 
      }


<h1 id="arc-challenge-advanced-reasoning-challenge">ARC-Challenge
(Advanced Reasoning Challenge)</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2018-03-14</p>
<p><strong>Name</strong>: ARC-Challenge Advanced Reasoning Challenge</p>
<p><strong>Domain</strong>: Science</p>
<p><strong>Focus</strong>: Grade-school science with reasoning
emphasis</p>
<p><strong>Keywords</strong>: grade-school, science QA, challenge set,
reasoning</p>
<p><strong>Task Types</strong>: Multiple choice</p>
<p><strong>Metrics</strong>: Accuracy</p>
<p><strong>Models</strong>: GPT-4, Claude</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Peter Clark, Isaac Cowhey, and Oren Etzioni. Think you have
solved question answering? try arc, the ai2 reasoning challenge. In
EMNLP 2018, 237 248. 2018. URL: https://allenai.org/data/arc.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="inproceedings">@inproceedings</span>{clark2018think,</p>
<pre><code>title={Think you have solved question answering? Try ARC, the AI2 Reasoning Challenge},

author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren},

booktitle={EMNLP 2018},

pages={237-248},

year={2018},

url={https://allenai.org/data/arc}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> No link to code or
documentation</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 2</p></li>
<li><p><strong>Reason:</strong> Task is clear, but no constraints or
format is mentioned</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Data accessible, offers instructions on
how to download the data via CLI tools. No splits.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> by default All questions in the dataset
are multiple choice, all have a correct answer</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 1</p></li>
<li><p><strong>Reason:</strong> There are over 300 models listed, but
very few, if any, show performance on the dataset or list
constraints</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Explains all necessary information
inside a paper</p></li>
</ul>
<p><strong>Average Rating:</strong> 2.833</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/arc-challenge_advanced_reasoning_challenge_radar.png"
alt="Arc-Challenge Advanced Reasoning Challenge radar plot" /></p>

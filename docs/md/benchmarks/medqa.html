<h1 id="medqa">MedQA</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2020-09-28</p>
<p><strong>Name</strong>: MedQA</p>
<p><strong>Domain</strong>: Medical Question Answering</p>
<p><strong>Focus</strong>: Medical board exam QA</p>
<p><strong>Keywords</strong>: USMLE, diagnostic QA, medical knowledge,
multilingual</p>
<p><strong>Task Types</strong>: Multiple choice</p>
<p><strong>Metrics</strong>: Accuracy</p>
<p><strong>Models</strong>: Neural reader, Retrieval-based QA
systems</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang,
and Peter Szolovits. What disease does this patient have? a large-scale
open domain question answering dataset from medical exams. 2020. URL:
https://arxiv.org/abs/2009.13081, arXiv:2009.13081.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{jin2020diseasedoespatienthave,</p>
<pre><code>  archiveprefix = {arXiv},

  author        = {Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung Weng and Hanyi Fang and Peter Szolovits},

  eprint        = {2009.13081},

  primaryclass  = {cs.CL},

  title         = {What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},

  url           = {https://arxiv.org/abs/2009.13081},

  year          = {2020}

}</code></pre>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> All code available on the
github</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 3</p></li>
<li><p><strong>Reason:</strong> Task is clearly defined as
multiple-choice QA for medical board exams; input and output formats are
explicit; task scope is rigorous and structured. System constraints not
specified.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Dataset is publicly available GitHub,
paper, Hugging Face , well-structured. However, versioning and metadata
could be more standardized to fully meet FAIR criteria.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Uses clear, quantitative metric accuracy
, standard for multiple-choice benchmarks; easily comparable across
models.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> No reference solution
mentioned.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Paper is available. Evaluation criteria
are not mentioned.</p></li>
</ul>
<p><strong>Average Rating:</strong> 3.5</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/medqa_radar.png" alt="Medqa radar plot" /></p>

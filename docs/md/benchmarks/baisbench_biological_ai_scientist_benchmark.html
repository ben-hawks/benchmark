<h1 id="baisbench-biological-ai-scientist-benchmark">BaisBench
(Biological AI Scientist Benchmark)</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2025-05-13</p>
<p><strong>Name</strong>: BaisBench Biological AI Scientist
Benchmark</p>
<p><strong>Domain</strong>: Computational Biology</p>
<p><strong>Focus</strong>: Omics-driven AI research tasks</p>
<p><strong>Keywords</strong>: single-cell annotation, biological QA,
autonomous discovery</p>
<p><strong>Task Types</strong>: Cell type annotation, Multiple
choice</p>
<p><strong>Metrics</strong>: Annotation accuracy, QA accuracy</p>
<p><strong>Models</strong>: LLM-based AI scientist agents</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Erpai Luo, Jinmeng Jia, Yifan Xiong, Xiangyu Li, Xiaobo Guo,
Baoqi Yu, Lei Wei, and Xuegong Zhang. Benchmarking ai scientists in
omics data-driven biological research. 2025. URL:
https://arxiv.org/abs/2505.08341, arXiv:2505.08341.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{luo2025benchmarkingaiscientistsomics,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Erpai Luo and Jinmeng Jia and Yifan Xiong and Xiangyu Li and Xiaobo Guo and Baoqi Yu and Lei Wei and Xuegong Zhang},

eprint        = {2505.08341},

primaryclass  = {cs.AI},

title         = {Benchmarking AI scientists in omics data-driven biological research},

url           = {https://arxiv.org/abs/2505.08341},

year          = {2025}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Instructions for environment setup
available</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Task clearly defined-cell type
annotation and biological QA; input/output formats are well-described;
system constraints are not quantified.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Uses public scRNA-seq datasets linked in
paper appendix; structured and accessible, though versioning and full
metadata not formalized per FAIR standards.</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Includes precise and interpretable
metrics annotation and QA accuracy ; directly aligned with task outputs
and benchmarking goals.</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> Model evaluations and LLM agent results
discussed; however, no fully packaged, runnable baseline confirmed
yet.</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Dataset and paper accessible; IPYNB
files for setup are available on the github repo.</p></li>
</ul>
<p><strong>Average Rating:</strong> 4.0</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/baisbench_biological_ai_scientist_benchmark_radar.png"
alt="Baisbench Biological Ai Scientist Benchmark radar plot" /></p>

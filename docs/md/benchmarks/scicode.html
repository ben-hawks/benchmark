<h1 id="scicode">SciCode</h1>
<p><strong>Edit:</strong> <a
href="https://github.com/mlcommons-science/benchmark/tree/main/source">edit
this entry</a></p>
<p><strong>Date</strong>: 2024-07-18</p>
<p><strong>Name</strong>: SciCode</p>
<p><strong>Domain</strong>: Scientific Programming</p>
<p><strong>Focus</strong>: Scientific code generation and problem
solving</p>
<p><strong>Keywords</strong>: code synthesis, scientific computing,
programming benchmark</p>
<p><strong>Task Types</strong>: Coding</p>
<p><strong>Metrics</strong>: Solve rate %</p>
<p><strong>Models</strong>: Claude3.5-Sonnet</p>
<p><strong>Citation</strong>:</p>
<ul>
<li><p>Minyang Tian, Luyu Gao, Shizhuo Dylan Zhang, Xinan Chen, Cunwei
Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat Krongchon, Yao Li,
Shengyan Liu, Di Luo, Yutao Ma, Hao Tong, Kha Trinh, Chenyu Tian, Zihan
Wang, Bohao Wu, Yanyu Xiong, Shengzhu Yin, Minhui Zhu, Kilian Lieret,
Yanxin Lu, Genglin Liu, Yufeng Du, Tianhua Tao, Ofir Press, Jamie
Callan, Eliu Huerta, and Hao Peng. Scicode: a research coding benchmark
curated by scientists. 2024. URL: https://arxiv.org/abs/2407.13168,
arXiv:2407.13168.</p>
<ul>
<li><p>bibtex: ``` <span class="citation"
data-cites="misc">@misc</span>{tian2024scicoderesearchcodingbenchmark,</p>
<pre><code>archiveprefix = {arXiv},

author        = {Minyang Tian and Luyu Gao and Shizhuo Dylan Zhang and Xinan Chen and Cunwei Fan and Xuefei Guo and Roland Haas and Pan Ji and Kittithat Krongchon and Yao Li and Shengyan Liu and Di Luo and Yutao Ma and Hao Tong and Kha Trinh and Chenyu Tian and Zihan Wang and Bohao Wu and Yanyu Xiong and Shengzhu Yin and Minhui Zhu and Kilian Lieret and Yanxin Lu and Genglin Liu and Yufeng Du and Tianhua Tao and Ofir Press and Jamie Callan and Eliu Huerta and Hao Peng},

eprint        = {2407.13168},

primaryclass  = {cs.AI},

title         = {SciCode: A Research Coding Benchmark Curated by Scientists},

url           = {https://arxiv.org/abs/2407.13168},

year          = {2024}</code></pre>
<p>}</p>
<p>```</p></li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<p>Software:</p>
<ul>
<li><p><strong>Rating:</strong> 5</p></li>
<li><p><strong>Reason:</strong> Code to run exists on github
repo</p></li>
</ul>
<p>Specification:</p>
<ul>
<li><p><strong>Rating:</strong> 4.5</p></li>
<li><p><strong>Reason:</strong> Expected outputs and broad types of
inputs stated. Few details on output grading. No HW
constraints.</p></li>
</ul>
<p>Dataset:</p>
<ul>
<li><p><strong>Rating:</strong> 0</p></li>
<li><p><strong>Reason:</strong> Paper and website had no link to any
dataset. It may still exist somewhere</p></li>
</ul>
<p>Metrics:</p>
<ul>
<li><p><strong>Rating:</strong> 2</p></li>
<li><p><strong>Reason:</strong> Metrics stated, but method of grading is
not specified</p></li>
</ul>
<p>Reference Solution:</p>
<ul>
<li><p><strong>Rating:</strong> 1</p></li>
<li><p><strong>Reason:</strong> Models presented with scores, but none
are open or list constraints</p></li>
</ul>
<p>Documentation:</p>
<ul>
<li><p><strong>Rating:</strong> 4</p></li>
<li><p><strong>Reason:</strong> Paper containing all needed info except
for evlauation criteria</p></li>
</ul>
<p><strong>Average Rating:</strong> 2.75</p>
<p><strong>Radar Plot:</strong> <img
src="../../tex/images/scicode_radar.png" alt="Scicode radar plot" /></p>
